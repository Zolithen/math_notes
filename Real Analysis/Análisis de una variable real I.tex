\documentclass{article}

\usepackage[spanish]{babel}
\usepackage{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[left=30pt,right=40pt,top=40pt,bottom=60pt]{geometry}

\newtheorem{theorem}{Teorema}
\newtheorem{prop}{Proposición}
\newtheorem{cor}{Corolario}
\newtheorem{axiom}{Axioma}
\newtheorem{define}{Definición}
\newtheorem{note}{Nota}
\newtheorem{ejem}{Ejemplo}

\DeclareMathOperator{\graf}{graf}

\author{NyKi}
\date{Diciembre 2024}

% Conjuntos
\newcommand{\reales}{\mathbb{R}}
\newcommand{\naturales}{\mathbb{N}}
\newcommand{\racionales}{\mathbb{Q}}
\newcommand{\protoreales}{\frac{\racionales}{\sim}}


\newcommand{\sucesion}[1]{\{ #1 _n \}_n}
\newcommand{\sucreal}[1]{\{ #1 _n \}_n \subseteq \reales}
\newcommand{\converge}[2]{#1 _n \rightarrow_{n} #2}
\newcommand{\limitesup}[1]{\limsup_{n\rightarrow +\infty} #1 _n}
\newcommand{\limiteinf}[1]{\liminf_{n\rightarrow +\infty} #1 _n}
\newcommand{\limiten}[1]{\lim_{n \rightarrow +\infty} #1}

% Operadores
\newcommand{\cerradura}[1]{\text{Cl}(#1)}
\newcommand{\interior}[1]{\text{Int}(#1)}
\newcommand{\frontera}[1]{\text{Fr}(#1)}

\begin{document}

\section{Introducción a los conjuntos numéricos}

\subsection{Construcciones}

\begin{note}
Las definiciones y construcciones de los conjuntos numéricos estándares aquí no se dan de una forma muy rigurosa. Su construcción es más propia de una asignatura de fundamentos matemáticos, y ahora mismo me da mucha pereza escribir todo. En este documento solo nos preocupará la construcción de los números reales, que haremos en la sección de sucesiones.
\end{note}

Sea $\mathbb{N}$ un conjunto con un elemento que denominamos 1. Ahora, para todo elemento $n$ de $\naturales$ añadimos a $\naturales$ el sucesor, $S(n)$ o $n+1$. Esto da un conjunto infinito, los \textbf{números naturales}. Generalmente, que $0$ esté dentro de $\mathbb{N}$ es una cuestión de comodidad. Aquí nos será mucho más cómodo que los números naturales empiecen en $1$.

En este conjunto tenemos el principio de inducción:

\begin{axiom}[Principio de inducción en $\naturales$]
Sea $S \subseteq \mathbb{N}$. Si $S$ satisface las siguientes 2 condiciones, entonces $S = \mathbb{N}$:
\begin{itemize}
\item
$1 \in S$
\item
$\forall n \in S \ n+1 \in S$
\end{itemize}
\end{axiom}

Este principio es muy útil para probar cosas sobre $\mathbb{N}$, por ejemplo la forma cerrada de una sucesión. En $\mathbb{N}$ también podemos definir algo denominado \textbf{orden total}, que es una relación binaria  $\leq$ que sigue los siguientes axiomas:
\begin{axiom}[Axiomas de orden total]
$\forall a,b,c \in \mathbb{N}$
\begin{enumerate}
	\item
	$a \leq a$ (Reflexividad)
	\item
	$a \leq b$ y $b \leq c$ implica $a \leq c$ (Transitivdad)
	\item
	$a \leq b$ y $b \leq a$ implica $a = b$ (Antisimetría)
	\item
	$a \leq b$ o $b \leq a$ (Totalidad o principio de tricotomía)
\end{enumerate}
\end{axiom}

Cuando tenemos un orden parcial o total definido sobre un conjunto, podemos hablar de cotas y máximos y mínimos:
\begin{define}
Sea $S \subseteq X$ donde $X$ es un conjunto con un orden parcial o total $\leq$. $S$ es...
\begin{itemize}
\item
\textbf{Acotado superiormente} si $\exists r \in X$ tal que $x \leq r\ \forall x \in S$.
\item
\textbf{Acotado inferiormente} si $\exists r \in X$ tal que $r \leq x\ \forall x \in S$.
\end{itemize}
Y decimos que un elemento $r \in S$ es...
\begin{itemize}
\item
Un \textbf{máximo} si $\forall x \in S\ x\leq r$.
\item
Un \textbf{mínimo} si $\forall x \in S\ r\leq x$.
\end{itemize}
\end{define}


Con este orden total definido, podemos reformular el principio de inducción como:

\begin{axiom}[Principio de buena ordenación en $\mathbb{N}$]
\label{ax_wellordering}
$\forall S \subseteq \mathbb{N}\ S\neq \emptyset,\exists n \in S\ |\ \forall x \in S, n\leq x$. Es decir, todo subconjunto de los números naturales tiene mínimo.
\end{axiom}

Estas dos formulaciones son equivalentes.
Los números naturales además cumplen los siguientes axiomas algebraicos:

\begin{axiom}[Axiomas de semianillo unitario ordenado]
\label{ax_usemiring}
$\forall a,b,c \in \mathbb{N}$:
\begin{enumerate}
	\item
	$(a+b)+c=a+(b+c)$ (Asociatividad de la suma)
	\item
	$a+b=b+a$ (Conmutatividad de la suma)
	\item
	$(a*b)*c=a*(b*c)$ (Asociatividad de la multiplicación)
	\item
	$a*b=b*a$ (Conmutatividad de la multiplicación)
	\item
	$a*(b+c) = a*b + a*c$ (Distributividad de la multiplicación sobre la suma)
	\item
	$\exists\ 1 \in \mathbb{N}\ |\ \forall n \in \mathbb{N},1*n = n$ (Elemento neutro del producto)
	\item
	$a \leq b \ \Rightarrow \ a+c\leq b+c$ (Compatibilidad del orden con la suma)
	\item
	Si $c\geq 0 $ (que es trivial en $\mathbb{N}$), entonces $a \leq b\ \Rightarrow \ ac \leq bc $ (Compatibilidad del orden con el producto)
\end{enumerate}
\end{axiom}

Estos axiomas son particularmente débiles. Por ejemplo, para la ecuación $x + 2 = 4$ obviamente $x = 2$, pero no existe ninguna forma de probarlo fácilmente, cuando la existencia de inversos para cada número ayudaría inmensamente. Además, ecuaciones como $x + 4 = 2$ no tienen solución en $\mathbb{N}$. Por eso definimos un nuevo conjunto denominado $\mathbb{Z}$, los \textbf{números enteros}:

\begin{define}[Números enteros]
$\mathbb{Z} = \mathbb{N} \cup \{0\} \cup \{-n\ \forall n \in \mathbb{N} \}$ donde $0$ denota la identidad para la suma y $-n$ el inverso para la suma de $n$. 
\end{define}

Estos números, ademas de los \textit{Axiomas \ref{ax_usemiring}}, cumplen los siguientes axiomas:

\begin{axiom}[Axiomas adicionales para $\mathbb{Z}$]\ 
\label{ax_additionalz}
\begin{enumerate}
	\item
	$\exists\ 0 \in \mathbb{Z}\ |\ \forall n \in \mathbb{N},0+n = n$ (Elemento neutro de la suma)
	\item
	$\forall n \in \mathbb{Z},\exists -n \in \mathbb{Z}\ |\ n+(-n)=0$ (Existencia del elemento inverso para la suma)
\end{enumerate}
\end{axiom}
Con estos axiomas, se dice que $(\mathbb{Z}, +)$ es un grupo conmutativo y que $(\mathbb{Z}, +, *)$ es un anillo conmutativo. A cambio de estos axiomas algebraicos, perdemos el principio de inducción en los números enteros y la existencia de un elemento mínimo, pero mantenemos una versión del principio de buena ordenación:

\begin{axiom}[Principio de buena ordenación de subconjuntos minorados de $\mathbb{Z}$]\ 
$\forall S \subseteq \mathbb{Z}\ S \neq \emptyset$ si $\exists n \in \mathbb{Z}\ |\ \forall x \in S,n\leq x$ entonces $\exists m \in S\ |\ \forall x \in S,m\leq x$. Es decir, todo subconjunto no vacío con cota inferior tiene un elemento mínimo.
\end{axiom}

Este axioma para $\mathbb{Z}$ implica el \textit{Axioma \ref{ax_wellordering}} para los naturales.
El conjunto de los números enteros aún tiene unos cuantos problemas. Por ejemplo, es imposible resolver la ecuación $2x=1$ para $x\in \mathbb{Z}$. Por eso, podemos definir otro conjunto de números construidos sobre los números enteros, los \textbf{números racionales}, denotados por $\mathbb{Q}$:

\begin{define}[Números racionales]
$\mathbb{Q} = \{ p/{q},p\in \mathbb{Z},q\in \mathbb{N}\}$
\end{define}

Aparte de cumplir los \textit{Axiomas \ref{ax_usemiring} y \ref{ax_additionalz}}, $\mathbb{Q}$ cumple:

\begin{axiom}[Axioma algebraico adicional para $\mathbb{Q}$]\ %fuck latex
\begin{enumerate}
	\item
	$\forall q \in \mathbb{Q}\ q \neq 0, \exists\ 1/q \in \mathbb{Q}\ |\ q * (1/q) = 1$ (Existencia del inverso de elementos no nulos para el producto)
\end{enumerate}
\end{axiom}

Esto hace de $\mathbb{Q}$ un cuerpo conmutativo. $\mathbb{Q}$ no tiene ni principio de buena ordenación, ni de buena ordenación de subconjuntos minorados (por ejemplo, el conjunto $S=\{ 1/n\ \forall n \in \mathbb{N}\}\subseteq \mathbb{Q}$ esta acotado inferiormente pero no tiene mínimo). Esto nos quita una vía de demostrar, pero "quitamos" más agujeros que existían en los números enteros:

\begin{theorem}[Densidad de $\mathbb{Q}$]
$\forall a,b \in \mathbb{Q}\ a \neq b,\ \exists r \in \mathbb{Q}\ |\ a<r<b$. Es decir, entre dos números racionales distintos siempre vamos a poder encontrar otro número racional. De hecho, vamos a poder encontrar infinitos aplicando el teorema cuantas veces como queramos.
\end{theorem}
\begin{proof}
Dados $a<b \in \mathbb{Q}$: $a = (a+a)/2 < (a+b)/2 < (b+b)/2 = b$. $(a+b)/2$ es el número que buscamos. 
\end{proof}
De este teorema podemos deducir que no existe una función sucesora en $\mathbb{Q}$, y por tanto no tenemos alternativa a inducción. Pero este teorema no es suficiente para que $\mathbb{Q}$ sea el conjunto numérico perfecto para hacer análisis. Aún existen agujeros, como demuestra el siguiente ejemplo:

\begin{prop}\label{prop_2_irrational}
No existe ningún $a \in \mathbb{Q}$ tal que $a^{2} = 2$.
\end{prop}
\begin{proof}
	Supongamos que $\exists a \in \mathbb{Q}$ tal que $a^2 = 2$. Al ser un número racional, lo podemos escribir de la forma $\frac{p}{q}$ con $p\in \mathbb{Z},q\in \mathbb{N}$ y $\gcd(p,q) = 1$ (donde $\gcd$ denota el máximo común divisor). Por tanto, tenemos la expresión $\frac{p^2}{q^2} = 2$, de donde deducimos que $p^2 = 2q^2$ y debido a que $2$ es un número primo, que $2|p$ o más concretamente $p=2k$ para algún $k \in \mathbb{Z}$. Substituyendo otra vez obtenemos $4k^2 = 2q^2$ y deducimos $2k^2 = q^2$, que de forma similar nos deja ver que $q$ es también múltiplo de 2. Pero inicialmente hemos asumido que el máximo común divisor de $p$ y $q$ es $1<2$ y no mayor o igual a $2$, por lo cual hemos encontrado una contradicción y la proposición es cierta.
\end{proof}
Esto es problemático, ya que intuitivamente deberíamos de poder encontrar un valor que cumpla $a^2 = 2$. Para poder arreglar este problema necesitamos una definición primero:

\begin{define}[Supremo e ínfimo]
	Sea $A$ un subconjunto numérico acotado superiormente. Si existe la mínima cota superior (es decir, un número $\omega$ que sea cota superior del conjunto y tal que cualquier otra cota superior $\alpha$ sea $\omega \leq \alpha$) esta será única y la llamaremos \textbf{supremo}. Dualmente, a la máxima cota inferior en un subconjunto acotado inferiormente la llamaremos \textbf{ínfimo}. Se denotan $\sup A$ y $\inf A$.
\end{define}
La definición parece ajena al ejemplo de ''agujero'' que hemos dado en la \textit{Proposición \ref{prop_2_irrational}}, pero es la más general que engloba todos los casos que necesitamos. El subconjunto $A\subseteq \mathbb{Q}$ definido como $A = \{a\in \mathbb{Q}\ |\ a^2 \leq 2\}$ esta acotado superiormente por $2$ y es posible demostrar que si existiera un supremo, este número sería tal que su cuadrado fuera igual a $2$, pero en $\mathbb{Q}$ no existe. Por tanto, podemos pensar que ''añadiendo todos los supremos'' completaríamos $\mathbb{Q}$. Este es el procedimiento que seguimos:
\begin{axiom}[Axioma del supremo] \label{ax_supr}
	Todo subconjunto acotado superiormente tiene supremo.
\end{axiom}
\begin{define}[Números reales]
	Al conjunto $\mathbb{R}$ con $\mathbb{Q} \subseteq \mathbb{R}$ y que cumpla el \textit{Axioma \ref{ax_supr}} lo llamamos los \textbf{números reales}.
\end{define}
Este conjunto no es único, pero si es único bajo isomorfismos, que viene a decir que cualesquiera dos conjuntos con estas propiedades tienen la misma estructura y por tanto no hace falta distinguirlos. Aquí no hemos dado una construcción de los números reales, lo que hemos dado aquí es solo una definición axiomática. Es decir, estamos asumiendo que existe un conjunto con estas características.




\subsection{Los números reales}
Empezamos el estudio de los números reales introduciendo algunos conceptos.
\begin{define}
El conjunto de los \textbf{irracionales} es $\mathbb{I} = \mathbb{R} \smallsetminus \mathbb{Q}$. Es decir, los números reales que no se pueden expresar como cociente de dos números enteros.
\end{define}

De esta definición podemos ver que un número real tiene que ser racional o irracional, pero no puede ser los dos a la vez. Esto implica que los racionales e irracionales forman una partición de los números reales.

\begin{define}[Valor absoluto]
Dado $x \in \mathbb{R}$ definimos el \textbf{valor absoluto} como:
\begin{equation}
|x| = \left\lbrace
\begin{array}{l}
x\ \text{si}\ x \geq 0 \\
\\
-x\ \text{si}\ x < 0
\end{array}
\right.
\end{equation}
\end{define}
El valor absoluto es de los conceptos mas fundamentales del análisis real. Geométricamente, si dibujamos el valor $x \in \mathbb{R}$ en la recta real, el valor absoluto da la longitud del segmento que va desde $x$ hasta $0$ y la distancia entre dos números reales en la recta real viene dada por $d(x, y) = |x-y|$.
\begin{prop}[Propiedades del valor absoluto]
$\forall a,b \in \mathbb{R}$ tenemos:
\begin{enumerate}
\item
$||a|| = |a|$
\item
$|-a| = |a|$
\item
$|ab| = |a||b|$
\item
La desigualdad triangular: $|a+b| \leq |a| + |b|$
\item
La desigualdad triangular inversa: $||a|-|b|| \leq |a-b|$
\item
Si $a\neq 0$ entonces $|\frac{1}{a}| = \frac{1}{|a|}$
\end{enumerate}
\end{prop}


La desigualdad triangular se usa mucho. Vamos a ver una caracterización del supremo e ínfimo:
\begin{prop}[Caracterización del supremo]
Sea $A\subseteq \mathbb{R}$.
\begin{enumerate}
\item
El supremo de $A$ existe si y solo sí existe un número $\omega \in \mathbb{R}$ que sea cota superior de $A$ tal que $\forall \varepsilon > 0$ exista $x \in A$ tal que $x > \omega - \varepsilon$. En este caso $\sup A = \omega$.

\item
El ínfimo de $A$ existe si y solo sí existe un número $\alpha \in \mathbb{R}$ que sea cota inferior de $A$ tal que $\forall \varepsilon > 0$ exista $x \in A$ tal que $x < \alpha - \varepsilon$. En este caso $\inf A = \alpha$.
\end{enumerate}
\end{prop}

\begin{proof}
	TODO: Añadir espacio\\ 
	Vamos a hacer la demostración en el caso del supremo, el caso del ínfimo es igual pero cambiando la dirección de las desigualdades.\\ 
	$\Rightarrow)$ Supongamos que existe el supremo de $A$, y sea $\omega = \sup A$. Si $\varepsilon > 0$ entonces $\omega - \varepsilon$ no será cota superior de $A$ (ya que el supremo es la mínima cota superior) y por tanto existirá $x \in A$ tal que $x > \omega - \varepsilon$. Además, $\omega$ es una cota superior de $A$, y así es el número que buscamos.\\ 
	$\Leftarrow)$ Tal $\omega$ es una cota superior por hipótesis, veamos que es la mínima. Sea $\alpha$ una cota superior distinta de $\omega$, y supongamos que $\alpha < \omega$. Sea $\varepsilon = \omega - \alpha > 0$. Por hipótesis existirá un $x \in A$ tal que $x > \omega - \varepsilon = \alpha$, que contradice que $\alpha$ sea cota superior de $A$. Esto también demuestra la unicidad del número que satisface las condiciones de $\omega$ (el supremo es único) y la última parte del enunciado.
\end{proof}

Cuando estudiemos sucesiones, nos será muy útil tener herramientas para relacionar los números naturales con los números reales.


\begin{theorem}[Propiedad arquimediana]
$\forall x,y \in \mathbb{R}$ tales que $x>0$ $\exists n \in \mathbb{N}$ con $nx>y$.
\end{theorem}
\begin{proof}
	Procedemos por contradicción. Supongamos que existen $x,y$ reales con $x > 0$ tales que para todo $n \in \naturales$ se tiene $nx \leq y$. Consideramos el conjunto $A = \{nx\ |\ n \in \naturales \}$ que no es vacío (ya que $\naturales$ no es vacío) y es acotado superiormente (por hipótesis). Por el axioma del supremo, existe el supremo de $A$. Sea $\alpha = \sup A$. Por la proposición anterior, tomando $\varepsilon = x > 0$ tendremos que existirá un $n \in \naturales$ tal que $nx > \alpha - \varepsilon = \alpha - x$, que implica $(n+1)x > \alpha$ pero como $n+1 \in \naturales$ se tiene $(n+1)x \in A$ y así $\alpha$ no sería una cota superior de $A$, que contradice la definición de supremo.
\end{proof}

Podemos entender el teorema así: si tenemos una longitud muy pequeña siempre vamos a juntar muchas de ellas para poder formar una longitud grande. Este teorema y la proposición anterior nos van a servir para demostrar corolarios que son intuitivamente verdad:
\begin{cor}
	El conjunto de los números naturales no está acotado superiormente.
\end{cor}
\begin{proof}
	Si $\naturales$ tuviera una cota superior, aplicando la propiedad arquimediana con $x=1$ e $y$ la cota superior tendríamos un número natural mayor que la cota superior, contradicción.
\end{proof}
Es importante notar lo que estamos demostrando: como subconjunto de $\reales$, $\naturales$ no está acotado superiormente. Si quisieramos demostrar que $\naturales$ no está acotado en los $\naturales$, simplemente notaríamos que $n+1 > n$. Esta distinción es importante, ya que vamos a trabajar con números reales la mayoría del tiempo.\\ 
TODO: Es necesario el corolario siguiente? Ponerlo con el otro corolario
\begin{cor}
	Todo subconjunto no vacío de los números naturales que esté acotado superiormente tiene máximo y mínimo.
\end{cor}
\begin{proof}
	Sea $A$ un subconjunto no vacío de números naturales. Tiene mínimo por el principio de inducción, y al estar acotado superiormente y no ser vacío existe el supremo que llamamos $\omega$. Si $\omega \not \in A$ tendríamos que para cada $n \in \naturales$ existiría un $x_n \in A$ tal que $\omega > x_n > \omega - \frac{1}{n}$. Considerando $x_{n+1}$ y $x_n$ en la desigualdad anterior llegamos a que $|x_{n+1} - x_n| < \frac{1}{n}$ y por tanto $x_{n+1} = x_n = x \in \naturales$ para todo $n \in \naturales$ (ya que $|x_{n+1} - x_n|$ será un número natural o $0$, pero ningún número natural es menor a $1$ por construcción). Como $x > \omega - \frac{1}{n}$ para todo $n$ se puede ver que $x \geq \omega$, pero también $\omega > x$, contradicción.
\end{proof}
\begin{cor}
	Un subconjunto no vacío de números naturales es finito si y solo sí está acotado si y solo sí tiene máximo.
\end{cor}
\begin{proof} 
	Es obvio que si se tiene un máximo entonces un subconjunto es acotado. Si un conjunto es acotado, por el corolario anterior tiene máximo. Esto demuestra la segunda doble implicación. Demostramos la primera doble implicación.\\ 
	$\Rightarrow)$ Demostramos que un conjunto $A \subseteq \naturales$ no vacío tiene máximo mediante inducción sobre el número de elementos del conjunto. Si tal conjunto tiene un único elemento, trivialmente ese elemento es el máximo. Supongamos entonces que todo subconjunto de $n$ elementos tiene máximo, y sea $A_{n+1}$ un conjunto con $n+1$ elementos. Escogiendo un elemento $a \in A_{n+1}$ tenemos $A_{n+1} = \{a \} \cup A_{n}$ con $A_{n}$ un conjunto de $n$ elementos, que por hipótesis tiene un máximo $a_n$. Entonces existen dos casos: $a_n > a$ y $a_n < a$. En el primero, $a_n$ es el máximo de $A_{n+1}$ y en el segundo $a$ es el máximo de $A_{n+1}$ por la transitividad del orden. En cualquier caso hemos encontrado el máximo de $A_{n+1}$.\\ 
	$\Leftarrow)$ Si $A$ es tal conjunto, por ser acotado $\exists \omega \in \reales$ cota superior de $A$. Aplicando la propiedada arquimediana con $x = 1, y = \omega$ encontramos que $\exists n_0 \in \naturales$ con $n_0 > \omega$, lo que implica que $n_0$ es cota superior de $A$, y además que $A \subseteq \{n\ |\ n\in\naturales \text{ y } n_0 \geq n \}$, siendo este último conjunto finito y por tanto $A$ es finito.
\end{proof}
\begin{cor}
	Todo subconjunto finito no vacío de los números reales esta acotado y tiene máximo y mínimo.
\end{cor}
\begin{proof}
	Demostramos el enunciado solo para el máximo, el mínimo se demuestra igual. Procedemos por inducción sobre el número $n$ de elementos del conjunto. El caso $n = 1$ es trivial. Supongamos que el enunciado es cierto para conjuntos con un número de elementos igual a $n$, y sea $A_{n+1}$ un conjunto con $|A_{n+1}| = n+1$. Sea $a$ un elemento cualquiera de $A_{n+1}$, y tenemos $A_{n+1} = \{a\} \cup A_{n}$ con $A_n$ un conjunto de $n$ elementos. Por hipótesis tendrá un máximo $b$, y por la ley de tricotomía  se tiene $a > b$ o $a < b$ (no se puede tener $a = b$ ya que son distintos). En el primer caso $a$ es el máximo de $A_{n+1}$ y en el segundo $b$ es el máximo de $A_n$
\end{proof}
\begin{cor}
	Un subconjunto no vacío de números enteros está acotado superiormente (resp. inferiormente) si y solo sí tiene máximo (resp. mínimo).
\end{cor}




\begin{theorem}[Existencia de la parte entera]
	$\forall x \in \mathbb{R}$ existe un único $k \in \mathbb{Z}$ tal que $k\leq x < k+1$.
\end{theorem}
\begin{proof}
	Sea $A = \{ k \in \mathbb{Z}\ |\ k \leq x\}$. Es un conjunto acotado superiormente y es no vacío por la propiedad arquimediana (tomando $y' = -x$  y $x' = 1$). Por tanto, tiene un máximo que llamamos $n$. Como $n+1 > n$ y $n$ es el supremo de $A$, $n+1 \not \in A$ lo que implica $n+1 > x$. $n$ es el número que buscamos.
\end{proof}

\begin{define}[Parte entera]
Dado $x \in \mathbb{R}$ definimos la \textbf{parte entera} como:
\begin{equation}
\lfloor x \rfloor = \sup \{k\in \mathbb{Z}\ |\ k\leq x\}
\end{equation}
Por el teorema anterior, este supremo siempre existe. También definimos la \textbf{parte fraccionaria} :
\begin{equation}
\{x\} = x - \lfloor x \rfloor
\end{equation}
\end{define}
Estos dos no son tan útiles como el valor absoluto.

\begin{define}[Potencias enteras]
Sea $x\in \mathbb{R}$ y $n\in \mathbb{Z}$. Definimos la \textbf{potencia n-ésima} de $x$ de forma inductiva, y la denotamos por $x^n$, como:
\begin{equation}
x^n = \left\lbrace
\begin{array}{l}
x * x^{n-1}\ \text{si}\ n > 1 \\
x\ \text{si}\ n = 1 \\
1\ \text{si}\ n = 0\ \text{y}\ x \neq 0 \\
\frac{1}{x^n}\ \text{si}\ n < 0\ \text{y}\ x \neq 0 \\
\end{array}
\right.
\end{equation}
Si $x = 0$ y $n \leq 0$ entonces la potencia queda indefinida. Al número $n$ se le llama \textbf{exponente}.
\end{define}

Es posible extender la definición de exponente a los números racionales e irracionales, pero se necesitan herramienta más fuertes para fundamentarlos. Esto lo veremos cuando introduzcamos las funciones, por ahora solo trabajaremos con las potencias racionales cuyo numerador sea $1$:

\begin{theorem}[Existencia de la raíz cuadrada]
Sea $a \in \mathbb{R}$ mayor o igual que $0$. Entonces existe un único $x \in \mathbb{R}$ mayor o igual que $0$ tal que $x^2 = a$.
\end{theorem}

\begin{theorem}[Existencia de raíces]
Sea $a \in \mathbb{R}$ cualquiera.
\begin{enumerate}
\item
Para todo $n \in \mathbb{N}$ impar existe un único $x\in \mathbb{R}$ tal que $x^n = a$.
\item
Si $a\geq 0$ entonces para todo $n \in \mathbb{N}$ par (recordamos que $\mathbb{N}$ no tiene el $0$ en nuestra definición) existe un único $x\in \mathbb{R}$ con $x\geq 0$ tal que $x^n = a$.
\end{enumerate}
En cualquier caso, al número $x$ lo llamaremos la \textbf{raíz n-ésima} de $a$ y lo denotaremos por $\sqrt[n]{a}$ o $a^{\frac{1}{n}}$.
\end{theorem}



\begin{prop}[Binomio de Newton]
Sean $x,y \in \mathbb{R}$ y $n \in \mathbb{N}$ entonces:
\begin{equation}
(x + y)^n = \sum_{m=0}^{n} {n \choose m} x^m y^{n-m}
\end{equation}
\end{prop}

Por conveniencia, definimos las sucesiones aquí:
\begin{define}
	Una \textbf{sucesión} es una aplicación $a: \mathbb{N} \rightarrow \mathbb{R}$. Por comodidad, la imagen de $n \in \mathbb{N}$ se denota por $a_n$ y para la sucesión en sí usaremos $\{a_n\}_n$. El conjunto $\{a_n\ : n \in \mathbb{N}\} \subseteq \mathbb{R}$ es el conjunto \textbf{imagen}. 
\end{define}
Introducir las sucesiones aquí nos va a permitir establecer algunos ejemplos de inducción:
\begin{ejem}[Números triangulares]
	Definimos la sucesión $\sucreal{T}$ mediante la fórmula $T_n = \sum_{k = 1}^{n} k$. Estos son los \textbf{números triangulares}. El objetivo es establecer una expresión cerrada para la sucesión. Para ello, vamos a intentar encontrar una posible fórmula cerrada y después usamos inducción para demostrarla. Primero notamos que
	\begin{equation}\label{ej_triang1}
		T_{n} - T_{n-1} = n 
	\end{equation}
	para todo $n > 1$. Veamos que también vamos a tener
	\begin{equation}\label{ej_triang2}
		T_{n} + T_{n-1} = n^2
	\end{equation}
	mediante un dibujo: \\ 
	En vista de esto, podemos sumar \eqref{ej_triang1} y \eqref{ej_triang2} para obtener
	\begin{equation*}
		2T_{n} = n^2 + n
	\end{equation*}
	y finalmente
	\begin{equation}\label{ej_triang}
		T_n = \frac{n(n+1)}{2}.
	\end{equation}
	Esta igualdad es la que vamos a demostrar por inducción. Primero vemos que \eqref{ej_triang} se cumple para $n=1$:
	\begin{equation*}
		T_1 = \sum_{k = 1}^{1} k = 1 = \frac{1*2}{2} = \frac{1(1+1)}{2}.
	\end{equation*}
	Ahora, suponemos que la expresión \eqref{ej_triang} es válida para un natural $n \geq 1$, y veamos que
	\begin{eqnarray*}
		T_{n+1} = \sum_{k = 1}^{n+1} k & = (n+1) + \sum_{k = 1}^{n} k \\ 
		& = (n+1) + T_n \\ 
		& = (n+1) + \frac{n(n+1)}{2} \\
		& = (n+1)(1+ \frac{n}{2}) \\  
		& = (n+1)\frac{2 + n}{2} \\  
		& = \frac{(n+1)((n+1) + 1)}{2}
	\end{eqnarray*}
	que es la expresión \eqref{ej_triang} con $n+1$, y por tanto queda demostrado.
\end{ejem}








\newpage
\section{Sucesiones de números reales}
\begin{define}Decimos que una sucesión $\{a_n\}_n \subseteq \mathbb{R}$ es:
	\begin{itemize}
		\item
		\textbf{Eventual creciente} si $\exists N \in \mathbb{N}$ tal que $a_m \geq a_n,\ \forall m>n\geq N$ con $n$ y $m$ naturales.
		\item
		\textbf{Eventual estrictamente creciente} si $\exists N \in \mathbb{N}$ tal que $a_m > a_n,\ \forall m>n\geq N$ con $n$ y $m$ naturales.
		\item
		\textbf{Eventual decreciente} si $\exists N \in \mathbb{N}$ tal que $a_m \leq a_n,\ \forall m>n\geq N$ con $n$ y $m$ naturales.
		\item
		\textbf{Eventual estrictamente decreciente} si $\exists N \in \mathbb{N}$ tal que $a_m < a_n,\ \forall m>n\geq N$ con $n$ y $m$ naturales.
	\end{itemize}
	En cualquier caso decimos que la sucesión es \textbf{eventual monótona}. Si $N = 1$ en cualquiera de estos casos, entonces quitamos ''eventual".
\end{define}
Nos interesa estudiar el comportamiento de la sucesión cuando $n$ se hace grande, es decir \textit{eventualmente}. Veremos que el comportamiento de $a_n$ cercano a $n = 1$ no importa
en lo que a límite se refiere, solo el comportamiento eventual. En los teoremas de sucesiones monótonas que hagamos generalmente no usaremos la monotonía eventual, sino la monotonía desde $n = 1$ pero también serán válidos para la eventual con pocas modificaciones.

\begin{define}
	Sea $\{ a_n\}_n \subseteq \mathbb{R}$ una sucesión de números reales. Decimos que $a_n$ está \textbf{acotada inferiormente} si existe un $A \in \mathbb{R}$ tal que para todo $n \in \mathbb{N}$ se tiene $a_n \geq A$. Análogamente, se dice que está \textbf{acotada superiormente} si existe un $B \in \mathbb{R}$ tal que para todo $n \in \mathbb{N}$ se tiene $a_n \leq B$. Se dice que está \textbf{acotada} si lo está superiormente e inferiormente.
\end{define}

\subsection{Convergencia}

\begin{define}
	Sea $\{ a_n\}_n \subseteq \mathbb{R}$ una sucesión de números reales. Decimos que $a_n$ \textbf{converge} a $L$ y lo denotamos como $a_n \rightarrow_{n} L$ si y solo si 
	$\forall \varepsilon > 0,\exists N \in \mathbb{N}$ tal que $|a_n - L| < \varepsilon$ para todo $n$ tal que $n \geq N$.
\end{define}
Esta definición se le conoce como definición $\delta-\varepsilon$.

\begin{prop}[Unicidad del límite]
	Sean $\{ a_n\}_n \subseteq \mathbb{R}$ convergente a $L_1$ y $L_2$. Entonces $L_1 = L_2$.
\end{prop}
\begin{proof}
	Supongamos que $L_1$ y $L_2$ son dos límites de la sucesión $\{ a_n\}_n \subseteq \mathbb{R}$. Por tanto, dado un $\varepsilon > 0$, existe un $N \in \mathbb{N}$ 
	tal que $|a_n - L_1| < \varepsilon/2$ y $|a_n - L_2| < \varepsilon/2\ $ $\forall n > N$ con $N=max\{n_1, n_2\}$, donde $n_1$ y $n_2$ son $N$ dado de la definición del límite para 
	$L_1$ y $L_2$. Sumando ambas desigualdades y usando la desigualdad triangular, tenemos:
	\begin{align*}
		\varepsilon = \frac{\varepsilon}{2} + \frac{\varepsilon}{2} > |a_n - L_1| + |a_n - L_2| = |a_n - L_1| + |-a_n + L_2| \\ \geq |a_n - L_1 - a_n + L_2| = |L_2 - L_1|
	\end{align*}
	Como $\varepsilon$ es un número arbitrario mayor que 0, si asumimos que $|L_2 - L_1| \neq 0$, siempre vamos a poder encontrar un valor de $\varepsilon$ (por ejemplo, 
	$\varepsilon = \frac{|L_2 - L_1|}{2} > 0$) mayor a 0 que contradiga $\varepsilon > |L_2 - L_1|$. Por tanto, $|L_2 - L_1| = 0$ y $L_2 = L_1$.
\end{proof}


\begin{define}
	Sabiendo que una sucesión convergente $\{ a_n\}_n \subseteq \mathbb{R}$ converge a un único valor $L$, llamamos a este valor \textbf{límite de la sucesión $a_n$}, y lo denotamos como
	$\lim_{n\rightarrow +\infty} a_n = L$ o de manera resumida $\lim_{n} a_n = L$.
\end{define}

\begin{ejem}
	Consideramos la sucesión $\sucreal{a}$ de término general $a_n = \frac{1}{n}$. Sea $\varepsilon > 0 $. Por la propiedad arquimediana existe un $N \in \naturales$ tal que $N\varepsilon > 1 \Rightarrow \varepsilon > |\frac{1}{N}|$. Si $n > N$ entonces $|\frac{1}{n} - 0| < |\frac{1}{N}| < \varepsilon$. Por tanto $\limiten{a_n} = 0$.
\end{ejem}


\begin{prop}
	Sea $\{ a_n\}_n \subseteq \mathbb{R}$ una sucesión de números reales. Si $\{ a_n\}_n$ converge, entonces es acotada.
\end{prop}

\begin{proof}
	Supongamos que $\sucreal{a}$ es una sucesión que converge a $L \in \reales$. Por la definición de convergencia existirá un $N \in \naturales$ tal que si $n \geq N$ entonces $|a_n - L| < 1$ (haciendo $\varepsilon = 1$). Podemos asegurar que $N > 1$ (si tuviéramos que $N = 1$ simplemente dejaríamos $N = 2$). Desarrollando el valor absoluto tenemos:
	\begin{align}\label{pf_random1}
		L - 1 < a_n < L + 1
	\end{align}	
	para todo $n \geq N$. Consideramos entonces los conjuntos $A = \{ a_1,\ a_2,\ \ldots,\ a_{N-1},\  L+1\}$ y $B = \{ a_1,\ a_2,\ \ldots,\ a_{N-1},\ L-1\}$. Como ambos conjuntos son finitos, podemos asegurar que existe el máximo de $A$ y el mínimo de $B$. Sean $\alpha = \min B$ y $\omega = \max A$. Entonces:
	\begin{enumerate}
	\item
	Si $n \in \naturales$ es tal que $1 \leq n < N$ entonces $a_n \in A$ y $a_n \in B$ y por tanto $\alpha \leq a_n \leq \omega$.
	\item
	Si $n \in \naturales$ es tal que $n \geq N$ entonces por \eqref{pf_random1} tenemos $\alpha \leq L - 1 \leq a_n \leq L + 1 \leq \omega$ y así $\alpha \leq a_n \leq \omega$ por la transitividad del orden.
	\end{enumerate}	 
	Como todo número natural es menor, igual o mayor que $N$ (principio de la tricotomía) tenemos que $\alpha \leq a_n \leq \omega$ para todo $n \in \naturales$ y por tanto la sucesión $\sucesion{a}$ está acotada.
\end{proof}

\begin{define}
	Si $\{ a_n\}_n \subseteq \mathbb{R}$ no converge a ningún valor $L\in\mathbb{R}$, podemos decir que $a_n$ es:
	\begin{itemize}
		\item
		\textbf{Divergente a $+\infty$} si $\forall M \in \mathbb{R},\ \exists N \in \mathbb{N}$ tal que $a_n > M\ \forall n>N$.
		
		\item
		\textbf{Divergente a $-\infty$} si $\forall M \in \mathbb{R},\ \exists N \in \mathbb{N}$ tal que $a_n < M\ \forall n>N$.
		
		\item
		\textbf{Oscilante} si no converge ni diverge.
	\end{itemize}
\end{define}


\begin{define}[Subsucesión]
	Sea $\{ n_k\}_k \subseteq \mathbb{N}$ una sucesión estrictamente creciente de números naturales y $\{ a_n\}_n \subseteq \mathbb{R}$ una sucesión cualquiera de números reales.
	Una \textbf{subsucesión de $a_n$} es una sucesión de la forma $\{ a_{n_k}\}_k \subseteq \mathbb{R}$.
\end{define}

\begin{theorem}[Aritmética de límites]
	Sean $\{ a_n\}_n \subseteq \mathbb{R}$ y $\{ b_n\}_n \subseteq \mathbb{R}$ dos sucesiones cualesquiera convergentes a $L_a$ y $L_b$ respectivamente. Entonces:
	\begin{itemize}
		\item
		Si $r \in \mathbb{R}$, entonces $\lim_{n\rightarrow +\infty} ra_n = rL_a$
		\item
		$\lim_{n\rightarrow +\infty} a_n + b_n = L_a + L_b$
		\item
		$\lim_{n\rightarrow +\infty} a_nb_n = L_aL_b$
		\item
		Si $b_n \neq 0\ \forall n \in \mathbb{N}$ y $L_b \not= 0$, entonces $\lim_{n\rightarrow +\infty} \frac{a_n}{b_n} = \frac{L_a}{L_b}$
	\end{itemize}
\end{theorem}


\begin{ejem}
\begin{enumerate}
\item
La sucesión $a_n = \frac{1}{n}$ converge a $0$ y es monótona decreciente. Además, toda subsucesión converge a $0$.
\item
La sucesión $a_n = n^3$ diverge a $+\infty$ y es monótona creciente.
\item
La sucesión 
\begin{equation}
a_n = \left\lbrace
\begin{array}{l}
1\ \text{si n es par}\\ 
-1\ \text{si n es impar}\
\end{array}
\right.
\end{equation}
es oscilante. Además, la subsucesión $\{a_{2n} \}_n$ converge a $1$ y $\{a_{2n+1} \}_n$ converge a $-1$.
\item
Las sucesiones $a_n = n$ y $b_n = -n$ divergen pero la sucesión $c_n = a_n + b_n$ converge a $0$.
\end{enumerate}
\end{ejem}

El comportamiento de las subsucesiones de una sucesión dada en relación a su convergencia es muy importante. Vemos unos resultados.

\begin{prop}
	Sea $\sucreal{a}$ una sucesión de números reales. Entonces converge si y solo si cada una de sus subsucesiones converge al mismo número.
\end{prop}

\begin{cor}
	Sea $\sucreal{a}$ una sucesión de números reales.
	\begin{enumerate}
		\item
		Si existe una subsucesión de $\sucesion{a}$ que no converge, entonces $\sucesion{a}$ no converge.
		\item
		Si existen dos subsucesiones que converjan a dos valores distintos entonces $\sucesion{a}$ no converge.
	\end{enumerate}
\end{cor}

Este corolario es muy útil para demostrar que algunas sucesiones no convergen. Ahora vamos a ver más resultados para poder saber cuando converge una sucesión y a qué converge.

\begin{theorem}[Convergencia de las sucesiones monótonas]
Sea $\sucreal{a}$ una sucesión de números reales, entonces:
\begin{enumerate}
\item
Si $\sucesion{a}$ es creciente, entonces converge si y solo si es acotada superiormente.
\item
Si $\{ a_n\}_n$ es decreciente, entonces converge si y solo si es acotada inferiormente. 
\end{enumerate}
\end{theorem}

Este es un ejemplo de teorema donde podríamos cambiar las suposiciones de creciente y decreciente por sus respectivas suposiciones eventuales. Esto cambiaría la demostración y el método de obtener el límite un poco.

\begin{theorem}[Orden de los límites y teorema del sandwich]
Sean $\sucreal{a}$, $\sucreal{b}$ y $\sucreal{c}$ tres sucesiones de números reales tales que $a_n \leq b_n \leq c_n$ para todo $n \in \naturales$.
\begin{enumerate}
\item
Si $\converge{a}{A}$, $\converge{b}{B}$ y $\converge{c}{C}$ entonces $A \leq B \leq C$.
\item
Si $\converge{a}{A}$ y $\converge{c}{C}$ y además $A = C$ entonces $\sucesion{b}$ converge a $A$.
\end{enumerate}
\end{theorem}

Finalmente, podemos constatar una relación del ínfimo y supremo con las sucesiones:

\begin{theorem}[Teorema de alcance]
	Sea $A \subseteq \reales$. 
\begin{enumerate}
\item
	Si $\exists \sup A$ entonces existe una sucesión de elementos de $A$ que converge a $\sup A$.
\item
	Análogamente, si $\exists \inf A$ entonces existe una sucesión de elementos de $A$ que converge a $\inf A$.
\end{enumerate}	

\end{theorem}







\subsection{Puntos de acumulación}
\begin{define}[Punto de acumulación]
	Sea $\sucreal{a}$ una sucesión de números reales. Si existe una subsucesión que converge a un número $L \in \reales$ entonces $L$ se dice que es un \textbf{punto de acumulación}.
\end{define}

\begin{theorem}[De Bolzano-Weierstrass]
\label{thm_bolzano_weierstrass}
	Toda sucesión acotada tiene una subsucesión convergente.
\end{theorem}

\begin{define}[Límites superior e inferior]
	Sea $\sucreal{a}$ una sucesión de números reales. 
	\begin{enumerate}
	\item
	Si $\sucesion{a}$ está acotada superiormente definimos el \textbf{límite superior} como $\limitesup{a} = \lim_{n \rightarrow +\infty} \sup\{ a_m : m > n\}$. Si $\sucesion{a}$ no está acotada superiormente lo definimos como $\limsup_{n\rightarrow +\infty} a_n = +\infty$
	\item
	Análogamente, si $\sucesion{a}$ está acotada inferiormente definimos el \textbf{límite inferior} como $\limiteinf{a} = \lim_{n \rightarrow +\infty} \inf\{ a_m : m > n\}$. Si $\sucesion{a}$ no está acotada inferiormente lo definimos como $\liminf_{n\rightarrow +\infty} a_n = -\infty$
	\end{enumerate}
\end{define}

Intuitivamente, el límite inferior y límite superior nos dicen el intervalo al que converge la sucesión:

\begin{prop}
	Sea $\sucreal{a}$ una sucesión. Entonces para todo $\varepsilon > 0$ existe un $N \in \naturales$ tal que si $m \geq N$ entonces $a_m \in [\limiteinf{a}-\varepsilon, \limitesup{a}+\varepsilon]$.
\end{prop}

Si la sucesión no es acotada, substituimos alguno de los límites del intervalo por $+\infty$ o $-\infty$.
Con esta proposición podemos demostrar otra caracterización de la convergencia de soluciones:

\begin{theorem}
	Sea $\sucreal{a}$ una sucesión. Entonces $\sucesion{a}$ converge si y solo si $\limiteinf{a} = \limitesup{a}$. En tal caso $\limiten{a_n} = \limitesup{a}$.
\end{theorem}

Los límites inferior y superior nos permiten hacer una pequeña extensión del teorema \eqref{thm_bolzano_weierstrass}:
\begin{prop}
\begin{enumerate}
\item
	El límite inferior y superior de una sucesión son puntos de acumulación de la misma.
\item
	Toda sucesión acotada tiene un punto de acumulación. Además es no convergente si y solo si es oscilante si y solo si tiene dos o más puntos de acumulación.
\end{enumerate}
\end{prop}


\begin{ejem}
	La sucesión $\{ a_n = \{\sqrt{n}\} \}_n$ tiene por lo menos dos puntos de acumulación:
	\begin{enumerate}
		\item
		Consideramos la subsucesión $b_m = a_{m^2}$, vemos que $b_m = \{\sqrt{m^2} \} = \{m \} = 0$ y como es constante converge a 0.
		\item
		Consideramos $c_m = a_{m^2 - 1}$. Primero constatamos la siguiente desigualdad:
		\begin{equation}
			\sqrt{m+1} - \sqrt{m-1} \geq \frac{1}{\sqrt{m+1}}
		\end{equation}				
		Que se puede comprobar fácilmente simplificando. Ahora notamos que si $m \geq 1$ entonces:
		\begin{equation*}
			m = \sqrt{m^2} > \sqrt{m^2 - 1} \geq \sqrt{m^2 - 2m + 1} = \sqrt{(m-1)^2} = m - 1
		\end{equation*}
		Y por tanto $\lfloor \sqrt{m^2 - 1} \rfloor = m - 1$, así tenemos que 
		
		\begin{align*}
			\begin{split}
				& 1 \geq c_m = \{\sqrt{m^2 - 1} \} = \sqrt{m^2 - 1} - \lfloor \sqrt{m^2 - 1} \rfloor =\\ & \sqrt{m^2 - 1} - (m - 1) = \sqrt{m-1}(\sqrt{m+1} - \sqrt{m-1})
				\geq  \frac{\sqrt{m-1}}{\sqrt{m+1}} = \sqrt{1 - \frac{2}{m+1}}
			\end{split}
		\end{align*}
		Y por el teorema del sandwich la subsucesión $c_m$ converge a $1$.\
	\end{enumerate}
	Como $a_n$ tiene por lo menos dos puntos de acumulación y $0 \leq a_n < 1$ para todo $n \in \naturales$ por la proposición anterior $\sucesion{a}$ es oscilante.
\end{ejem}

\begin{prop}
	Si una sucesión tiene por lo menos un punto de acumulación entonces no puede diverger.
\end{prop}

\begin{ejem}
	La sucesión $\sucreal{a}$ definida por:
	\begin{equation}
		a_n = \left\lbrace
		\begin{array}{l}
		0\ \text{si existe}\ m \in \naturales\ \text{con}\ n = 3m\\
		1\ \text{si existe}\ m \in \naturales\ \text{con}\ n = 3m + 1\\
		n\ \text{si existe}\ m \in \naturales\ \text{con}\ n = 3m + 2\\
		\end{array}
		\right.
	\end{equation}
	tiene $0$ y $1$ como puntos de acumulación, es oscilante pero no es acotada.
\end{ejem}

\begin{ejem}[Una sucesión con infinitos puntos de acumulación]
	Vamos a construir una sucesión que tenga como conjunto de puntos de acumulación todos los números naturales. Es posible usar esta sucesión para poder construir otra tal que el conjunto de puntos de acumulación sean todos los reales, pero la construcción es algo más ortopédica y la demostración mas engorrosa.
	El objetivo es construir la siguiente sucesión: $1,\ 1,\ 2,\ 1,\ 2,\ 3,\ 1,\ 2,\ 3,\ 4 \ldots\ $, para esto usamos los números triangulares.
	Sea $\sucreal{b}$ la sucesión de los números triangulares más uno, es decir $b_n = \frac{n(n+1)}{2} + 1$ para todo $n \in \naturales$. Sabemos que esta sucesión es estrictamente creciente y que $b_0 = 1,\ b_1 = 2$ (por comodidad añadimos el término cero). Definimos la sucesión $\sucreal{a}$ como:
	\begin{equation*}
		a_n = n - b_{m-1} + 1\ \text{para m} \in \naturales\ \text{tal que}\ b_{m-1} \leq n \leq b_m \text{.}
	\end{equation*}
	Para cualquier $n \in \naturales$ existe un único $m \in \naturales$ que satisfaga la igualdad, así que está bien definida. (TODO: Terminar demostración)
\end{ejem}

Los límites superior e inferior no tienen mucho interés práctico. Sirven por ejemplo para obtener refinamientos de teoremas como el criterio de Stolz.

\subsection{El número e}

\begin{define}
	Definimos el número $e$ como $e = \lim_{n \rightarrow \infty} \sum_{m=1}^{n} \frac{1}{m!}$. 
\end{define}

\begin{prop}
	El límite en la definición del número $e$ existe.
\end{prop}

\begin{prop}
	$\lim_{n \rightarrow \infty} \sum_{m=1}^{n} \frac{1}{m!} = \lim_{n \rightarrow \infty} (1 + \frac{1}{n})^n$.
\end{prop}

\begin{prop}
	El número $e$ es irracional.
\end{prop}
Resulta que $e$ también es más que irracional, es \textit{transcendental}. Esto es una cualidad meramente algebraica de demostración más complicada, que no trataremos aquí.

\subsection{Sucesiones de Cauchy y completitud}
\begin{define}
	Sea $\sucreal{a}$ una sucesión. Decimos que es una \textbf{sucesión de Cauchy} si para todo $\varepsilon > 0$ existe un $N \in \naturales$ tal que si $m,\ n \in \naturales$ son números naturales mayores o iguales que $N$ se tiene $|a_n - a_m| < \varepsilon$.
\end{define}
El objetivo de esta definición es tener una propiedad equivalente a la convergencia sin necesitar de saber el límite de una sucesión. Este hecho es muy importante:
\begin{theorem}[Completitud de $\reales$]
	Sea $\sucreal{a}$ una sucesión. Entonces $\sucesion{a}$ converge si y solo si es de Cauchy.
\end{theorem}
El resultado importante aquí es que una sucesión de Cauchy converge, y en algunos textos esto es lo que se llama completitud.
La completitud se puede generalizar a espacios métricos generales, y podemos hablar de \textit{completitud} en subconjuntos de $\reales$:
\begin{ejem}[Los racionales no son completos]
	Sea $A \subseteq \racionales$ definido como $A = \{ a\in \racionales\ :\ a^2 < 2\}$. Entonces $\sqrt{2} \not\in \racionales$ es el supremo de este conjunto en los reales, y por tanto existirá una sucesión de elementos de $A$ que converge a $\sqrt{2}$, vamos a llamarla $\sucesion{a} \subseteq \racionales$. En los reales la sucesión converge, y por el teorema de completitud es de Cauchy. Como es de Cauchy en los reales entonces es de Cauchy en los racionales, pero como converge a $\sqrt{2}$ y este número es irracional al existir un único límite para toda sucesión convergente, concluimos que no converge en $\racionales$.
\end{ejem}
Podemos usar las sucesiones de Cauchy para hacer una construcción de los números reales.








\subsection{Cálculo de límites}
Ahora vamos a dar unos cuantos teoremas para calcular límites.

\begin{theorem}[Criterio de Cauchy o de la raíz]
	Sea $\sucreal{a}$ una sucesión tal que
	\begin{equation*}
		\lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n} = L
	\end{equation*}
	con $L$ finito. Entonces
	\begin{equation*}
		\lim_{n \rightarrow \infty} \sqrt[n]{a_n} = L.
	\end{equation*}
\end{theorem}

\begin{theorem}[Criterio de Stolz]

\end{theorem}

\begin{theorem}[Criterio de la media aritmética]
	Sea $\sucreal{a}$ una sucesión de números reales que converja a $L \in \reales$. Entonces se tiene
	\begin{equation*}
		 \lim_{n \rightarrow \infty} \frac{\sum_{m=1}^{n} a_m}{n} = L.
	\end{equation*}
\end{theorem}

\begin{theorem}[Criterio de la media geométrica]
	Sea $\sucreal{a}$ una sucesión de números reales que converja a $L \in \reales$. Entonces se tiene
	\begin{equation*}
		 \lim_{n \rightarrow \infty} \sqrt[n]{\prod_{m=1}^{n} a_m} = L.
	\end{equation*}
\end{theorem}














\newpage
\section{Introducción a la topología de los números reales}

El objetivo de introducir conceptos topológicos aquí es proporcionar la idea de estar infinitamente cerca y estar lejos de un conjunto.

\begin{define}
\begin{enumerate}
	\item
	Un conjunto $A \subseteq \reales$ se dice \textbf{abierto} si y solo si para todo $a \in A$ existe un $\varepsilon > 0$ tal que $(a - \varepsilon, a + \varepsilon) \subseteq A$.
	\item 
	Un conjunto $C \subseteq \reales$ se dice \textbf{cerrado} si y solo si el complementario $\reales \setminus C$ es abierto.
\end{enumerate}
\end{define}

Un conjunto abierto es tal que todo punto no esté infinitamente cerca del complementario. Así, un conjunto cerrado es aquel en el que todo punto fuera de él esta ``lejos".

\begin{ejem}
	$\reales$, el conjunto vacío y todo intervalo abierto son conjuntos abiertos.
\end{ejem}

\begin{define}[Puntos especiales de un conjunto]
	Sea $A \subseteq \reales$ un conjunto cualquiera.
	\begin{enumerate}
		\item
		Un punto $x \in A$ se dice \textbf{punto interior} si y solo si existe un $\varepsilon > 0$ tal que $(x - \varepsilon, x + \varepsilon) \subseteq A$.
		\item
		Un punto $x \in \reales$ se dice \textbf{punto límite} si y solo si existe una sucesión $\sucesion{a} \subseteq A$ que converge a $x$.
		\item
		Un punto $x \in \reales $ se dice \textbf{punto de acumulación} si y solo si existe una sucesión $\sucesion{a} \subseteq A$ que converge a $x$ tal que $a_n \neq x$ para todo $n \in \naturales$.
		\item
		Un punto límite de $A$ que no es de acumulación se dice \textbf{punto aislado}.
		\item
		Se dice que $A$ es un \textbf{entorno} de un punto $x \in A$ si y solo si $x$ es un punto interior de $A$.
	\end{enumerate}
\end{define}

\begin{prop}
	Sea $A \subseteq \reales$ un conjunto cualquiera. Entonces siempre existe un menor conjunto cerrado que contiene a $A$ y un mayor conjunto abierto contenido en $A$.
\end{prop}

Podemos usar esta proposición para estas definiciones:

\begin{define}[Conjuntos asociados]
	Sea $A \subseteq \reales$ un conjunto cualquiera.
	\begin{enumerate}
		\item
		Definimos la \textbf{cerradura} de $A$ como el menor conjunto cerrado que contiene a $A$ y lo denotamos por $\cerradura{A}$.
		\item
		Definimos el \textbf{interior} de $A$ como el mayor conjunto abierto contenido en $A$ y lo denotamos por $\interior{A}$.
		\item
		Definimos la \textbf{frontera} de $A$ como el conjunto $\frontera{A} = \cerradura{A} \setminus \interior{A}$.
	\end{enumerate}
\end{define}

\begin{prop}
	Sea $A \subseteq \reales$ un conjunto cualquiera.
	\begin{enumerate}
		\item
		$\cerradura{A}$ es igual a la intersección de todos los cerrados que contienen a $A$ y también al conjunto de todos los puntos límite de $A$.
		\item
		$\interior{A}$ es igual a la unión de todos los abiertos contenidos en $A$ y también al conjunto de todos los puntos interiores de $A$.
	\end{enumerate}
\end{prop}

\begin{prop}
	Sea $A \subseteq \reales$ un conjunto cualquiera.
	\begin{enumerate}
		\item
		$A$ es abierto si y solo si $A = \interior{A}$.
		\item
		$A$ es cerrado si y solo si $A = \cerradura{A}$.
	\end{enumerate}
\end{prop}

\begin{prop}
	\begin{enumerate}
		\item
		La unión arbitraria de conjuntos abiertos es abierta.
		\item
		La intersección finita de conjuntos abiertos es abierta.
		\item
		La intersección arbitraria de conjuntos cerrados es cerrada.
		\item
		La unión finita de conjuntos cerrados es cerrada.
	\end{enumerate}
\end{prop}

Hay un corolario importante del teorema de Bolzano-Weierstrass para sucesiones:

\begin{theorem}
	Todo conjunto infinito y acotado tiene por lo menos un punto de acumulación.
\end{theorem}

\begin{note}
	Los términos introducidos aquí reciben múltiples definiciones, nombres y notaciones distintas dependiendo de que libros y apuntes se miren. Otras notaciones incluyen $\overline{A}$ para la cerradura, $\mathring{A}$ para el interior y $\partial A$ para la frontera. La cerradura también se llama clausura o adherencia, y la frontera se le puede llamar borde también. Generalmente, para las distintas definiciones se suele presentar una como ``la definición'' y las otras como teoremas de equivalencia, que es lo que he hecho aquí.
\end{note}

\begin{define}
	Sea $A \subseteq \reales$ y $\mathcal{A}$ una familia de subconjuntos abiertos de $\reales$. Decimos que $\mathcal{A}$ \textbf{cubre} o que es un \textbf{cubrimiento por abiertos} de $A$ si y solo si la unión de todos los conjuntos de $\mathcal{A}$ contiene a $A$.
\end{define}

\begin{define}
	Un conjunto $A \subseteq \reales$ se dice \textbf{compacto} si y solo si de todo cubrimiento por abiertos de $A$ se puede obtener una subfamilia (llamada \textbf{subrecubrimiento}) de cardinal finito que sigue cubriendo $A$.
\end{define}

\begin{theorem}[Heine-Borel]
	Un subconjunto de $\reales$ es compacto si y solo si es acotado y cerrado.
\end{theorem}




\newpage
\section{Funciones, límites y continuidad}
\begin{define}[Funciones]
	Una aplicación $f:A \rightarrow B$ con $A$ y $B$ subconjuntos de $\reales$ (preferentemente no vacíos) se llama \textbf{función real de una variable real} o simplemente \textbf{función}.
\end{define}

Hay muchos detalles sobre esta definición. Al conjunto $A$ lo llamamos \textbf{dominio} y al conjunto $B$ \textbf{codominio}. Si $C \subseteq \reales$ el conjunto $f(C) = \{f(a)\ : a \in A \cap C \}$ se denomina conjunto \textbf{imagen de C}, el conjunto $f(A)$ se denomina simplemente \textbf{imagen}. Generalmente es mucho trabajo indicar siempre el dominio, codominio y definición de todas las funciones que usamos. Es por eso que nos tomamos la libertad de excluir ciertos componentes de la definición cuando hablamos de funciones, si pueden quedar claros. Por ejemplo: 

\begin{ejem}[Definiciones de funciones]
	\begin{enumerate}
		\item
		$f:\reales \rightarrow \reales$ tal que $f(x) = x^2\ \forall x \in \reales$. En este ejemplo tenemos explícitamente el dominio y el codominio.
		\item
		$g(x) = \sqrt{x^2 - 1}$. Aquí no hemos incluido ni el dominio ni el codominio en la definición de la función. Por tanto, asumimos que el codominio es $\reales$ y que el dominio es donde la regla de definición sea válida, es decir donde $x^2 - 1 \geq 0$
		\item
		$h(x) = \sqrt{-x^2 - 1}$. En este caso la regla dada no define una función ya que no es válida para ningún valor de $x$. Técnicamente, obtendríamos una aplicación con dominio vacío, pero introducir este tipo de funciones en la teoría no aporta nada relevante, así que se ignoran.
	\end{enumerate}
\end{ejem}

En la mayoría de ocasiones en nuestras definiciones asumiremos que el codominio es $\reales$, y asumiremos tácitamente que podemos extenderlas a casos donde el codominio sean otros subconjuntos reales.\\ 
Espero que el lector haya visto ya algunas funciones importantes. Usando funciones ya dadas podemos construir nuevas funciones (esto es un hecho intuitivo):
\begin{define}
	Sean $f:A \rightarrow \reales$ y $g:B \rightarrow \reales$ con $A,B \subseteq \reales$. Definimos:
	\begin{enumerate}
		\item
		Si $A \cap B \neq \emptyset$, la suma $f + g : A \cap B \rightarrow \reales$ por $(f + g)(x) = f(x) + g(x)\ \forall x \in A \cap B$.
		\item
		Si $A \cap B \neq \emptyset$, la multiplicación $fg : A \cap B \rightarrow \reales$ por $(fg)(x) = f(x)g(x)\ \forall x \in A \cap B$.
		\item
		El opuesto de f, $-f: A \rightarrow \reales$ por $(-f)(x) = -f(x)\ \forall x \in A \cap B$.
		\item
		$\frac{1}{f}: C \rightarrow \reales$ donde $C = \{x \in A\ |\ f(x) \neq 0\}$ (si $C$ no es vacío) por $(\frac{1}{f}(x)) = \frac{1}{f(x)}\ \forall x \in A$.
		\item
		Si $g(B) \cap A \neq \emptyset$, la composición $f \circ g : C \rightarrow \reales$ donde $C = \{x \in B\ |\ g(x) \in A\}$ por $(f \circ g)(x) = f(g(x))\ \forall x \in C$.
	\end{enumerate}
\end{define}
Lo importante de esta definición es la composición. Veremos que generalmente es más complicado tratar con composiciones de funciones que con sumas o multiplicaciones.\\
Al igual que las sucesiones, las funciones pueden estar acotadas o ser monótonas.
\begin{define}[Acotaciones]
	Sea $f:A \rightarrow \reales$ una función. Decimos que:
	\begin{enumerate}
		\item
		$f$ está \textbf{acotada superiormente} si existe un $\alpha \in \reales$ tal que $f(x) \leq \alpha\ \forall x \in A$.
		\item
		$f$ está \textbf{acotada inferiormente} si existe un $\alpha \in \reales$ tal que $f(x) \geq \alpha\ \forall x \in A$.
		\item
		$f$ está \textbf{acotada} si lo está superiormente e inferiormente.
	\end{enumerate}
\end{define}

\begin{define}[Monotonía de funciones]
	Sea $f:A \rightarrow \reales$ una función.
	\begin{enumerate}
		\item
		$f$ es \textbf{creciente} si $f(x) \leq f(y)$ para cualesquiera $x,y \in A$ tales que $x < y$.
		\item
		$f$ es \textbf{decreciente} si $f(x) \geq f(y)$ para cualesquiera $x,y \in A$ tales que $x < y$.
	\end{enumerate}
	Si las desigualdades son estrictas, se tienen funciones \textbf{estrictamente crecientes} y \textbf{estrictamente decrecientes}. En cualquiera de estos casos, la función $f$ se dice que es \textbf{monótona}.
\end{define}

\begin{define}[Máximos y mínimos]
	Sea $f:A \rightarrow \reales$ una función. Se dice que
	\begin{enumerate}
		\item
		$f$ tiene un \textbf{máximo global} en $a \in A$ si $f(a) \geq f(x)$ para todo $x \in A$ distinto de $a$.
		
		\item
		$f$ tiene un \textbf{mínimo global} en $a \in A$ si $f(a) \leq f(x)$ para todo $x \in A$ distinto de $a$.
			
		\item
		$f$ tiene un \textbf{máximo local} en $a \in A$ si existe un entorno $E$ de $a$ tal que $f(a) \geq f(x)$ para todo $x \in E$ distinto de $a$.
		
		\item
		$f$ tiene un \textbf{mínimo local} en $a \in A$ si existe un entorno $E$ de $a$ tal que $f(a) \leq f(x)$ para todo $x \in E$ distinto de $a$.
	\end{enumerate}
	Si las desigualdades son estrictas, añadimos el adjetivo \textbf{estricto} al final, por ejemplo máximo local estricto.
\end{define}

\begin{ejem}
	\begin{enumerate}
		\item
		La función $f(x) = x^2$ es decreciente en $(-\infty, 0]$ y creciente en $[0, +\infty]$. Además, esta acotada inferiormente pero no superiormente. En intervalos finitos está acotada.
		\item
		La función $f: \reales \setminus \{ 0\} \rightarrow \reales$ dada por $f(x) = \frac{1}{x}$ no está acotada. Presenta en $x = 0$ una asíntota vertical.
		\item
		La función $f: \reales \rightarrow \reales$ definida por:
		\begin{equation*}
			f(x) = \left\lbrace
			\begin{array}{l}
			0\ \text{si }\ x \not \in \racionales \text{ o } x = 0\\
			p\ \text{si }\ x \in \racionales \text{,}\ x \neq 0 \text{, y}\ \exists p,q \in \naturales \text{ tales que } x = \frac{p}{q}\  \text{y}\ \gcd(p,q) = 1\\
			-p\ \text{si }\ x \in \racionales \text{,}\ x \neq 0 \text{, y}\ \exists p,q \in \naturales \text{ tales que } x = \frac{-p}{q}\  \text{y}\ \gcd(p,q) = 1 \\
			\end{array}
			\right.
		\end{equation*}
		está acotada inferiormente, pero no superiormente. Además, sobre todo intervalo acotado la función no es acotada superiormente.
	\end{enumerate}
\end{ejem}

El último ejemplo es "patológico``: es una función definida en todo $\reales$, que no está acotada en ningún intervalo acotado (que no sean un único punto) y no presenta ninguna asíntota en el sentido de la función $f(x) = \frac{1}{x}$. No tiene ningún interés más.\\ 
Presentamos ahora definiciones de la teoría de conjuntos:
\begin{define}
	Sea $f:A \rightarrow B$ con $A,B \subseteq \reales$ una función. Decimos que $f$ es:
	\begin{enumerate}
		\item
		\textbf{Inyectiva}, sí $f(x) = f(y)$ implica $x = y$ para todo $x,y \in A$.
		\item
		\textbf{Suprayectiva} (o suryectiva), si $f(A) = B$.
		\item
		\textbf{Biyectiva}, si es inyectiva y suprayectiva.
	\end{enumerate}
\end{define}

\begin{ejem}
	\begin{enumerate}
		\item
		La función $f: \reales \rightarrow \reales$ dada por $f(x) = x^2$ no es inyectiva mientras que $g: [0, +\infty] \rightarrow \reales$ dada por $g(x) = x^2$ sí que lo es.
	\end{enumerate}
\end{ejem}

Las funciones biyectivas son importantes, ya que son aquellas que como a cada elemento de la imagen le corresponde un elemento del dominio se pueden invertir:
\begin{define}
	Dada una aplicación $f: A \rightarrow B$ biyectiva definimos la \textbf{aplicación inversa} a la aplicación biyectiva $f^{-1}: B \rightarrow A$ dada por la regla $f^{-1}(b) = a$ si y solo si $f(a) = b$.
\end{define}
\begin{proof}
	Es necesario demostrar que esta regla define una aplicación biyectiva. Sea $b \in B$ cualquiera. Por ser $f$ suprayectiva $\exists a \in A$ tal que $f(a) = b$ y por ser inyectiva si $a' \in A$ es otro elemento tal que $f(a') = f(a) = b$ entonces $a' = a$. Por tanto tal $a$ es único y la regla define una aplicación. Ahora bien, si $a \in A$ entonces $f^{-1}(f(a)) = b$ por definición y por tanto $f^{-1}$ es suprayectiva. Además, si $a = f^{-1}(b) = f^{-1}(b')$ para algunos $b, b' \in B$ y $a \in A$ entonces $f(a) = b' = b$ y por tanto $f$ también es inyectiva.
\end{proof}

También decimos que una aplicación biyectiva es inversible o invertible.\\ 
La mayoría de funciones que nos vamos a encontrar no van a ser biyectivas, pero serán especialmente importantes a la hora de hablar de cosas específicas como la regla de la cadena o el cambio de variable en integrales. En el caso que una función sea inyectiva, es posible ``restringir'' el codominio para obtener una aplicación biyectiva y por tanto inversible. En estos casos decimos que la aplicación original es inversible, y tomaremos su inversa como la inversa de la nueva aplicación. No llevaremos mucho cuidado con esta terminología.\\ 
Si una función no es inversible, aún podemos darle sentido a la notación $f^{-1}$:

\begin{define}
	Dada una función $f: A \rightarrow \reales$ y un subconjunto $B \subseteq \reales$ definimos la \textbf{preimagen} de $B$ bajo $f$ como el conjunto $f^{-1}(B) = \{x \in A\ | \ f(x) \in B \}$.
\end{define}

Por último, dejamos más definiciones que son parcialmente importantes:

\begin{define}
	Dada una función $f: A \rightarrow \reales$ definimos la \textbf{gráfica} de $f$ como el conjunto $\graf f = \{(x, f(x)) : x \in A \} \subseteq \reales^2$.
\end{define}

\begin{define}
	Dada una función $f: A \rightarrow \reales$ decimos que es:
	\begin{itemize}
		\item
		\textbf{Par} si se cumple $f(x) = f(-x)$ para todo $x \in A$ con $-x \in A$.
		
		\item
		\textbf{Impar} si se cumple $-f(x) = f(-x)$ para todo $x \in A$ con $-x \in A$.
	\end{itemize}
\end{define}

\begin{define}
	Una función $f: \reales \rightarrow \reales$ se dice \textbf{periódica} si existe un $L\in \reales$ tal que $f(x+L) = f(x)\ \forall x \in \reales$, y $L$ se denomina un \textbf{periodo} de la función. Si existe un mínimo $L$ distinto de cero que cumpla lo anterior, se le llama \textbf{período fundamental}.
\end{define}

\begin{ejem}
	\begin{itemize}
		\item
		$x^2, \cos x, |x|$ son funciones pares, $x^3, \sen x, \frac{1}{x}$ son impares mientras que $e^x$ no es ni par ni impar.
		\item
		Los ejemplos clásicos de funciones periódicas son las funciones constantes y las trigonométricas. En el primer caso no existen período fundamental, en el segundo por ejemplo para las funciones $\sin$ y $\cos$ el período fundamental es de $2\pi$.
	\end{itemize}
\end{ejem}


\subsection{Límites}
El concepto de límite formaliza la idea de \textit{acercarse}. Para una función, podemos ver a que valor se acerca al ir a infinito o cuando tiende a un punto. Esto significa que tenemos que tratar con distintos tipos de límites:

\begin{define}
	\begin{itemize}
		\item
		Sea $f: (a, \infty) \rightarrow \reales$. Decimos que $f$ \textbf{converge} a un valor $L\in \reales$ en el infinito positivo si $\forall \varepsilon > 0$ existe un $\delta > 0$ tal que si $x > \delta$ se tiene $|f(x) - L| < \varepsilon$. Si en cambio ocurre que $\forall K \in \reales$ existe un $\delta > 0$ tal que si $x > \delta$ se tiene $f(x) > K$ entonces decimos que $f$ \textbf{diverge a $+\infty$}. Análogamente se pueden definir para el infinito negativo y para $-\infty$.
		\item
		Sea $f: A \rightarrow \reales$ y $p$ un punto de acumulación de $A$. Decimos que $f$ \textbf{converge} a un valor $L\in \reales$ en $p$ si $\forall \varepsilon > 0$ existe un $\delta > 0$ tal que si $|x - p| < \delta$ se tiene $|f(x) - L| < \varepsilon$. Si en cambio ocurre que $\forall K \in \reales$ existe un $\delta > 0$ tal que si $|x - p| < \delta$ se tiene $f(x) > K$ entonces decimos que $f$ \textbf{diverge a $+\infty$} en $p$. Análogamente se define para $-\infty$.
		\item
		Sea $f: (p, b) \rightarrow \reales$. Decimos que $f$ \textbf{converge por la derecha} a un valor $L \in \reales$ en $p$ si $\forall \varepsilon > 0$ existe un $\delta > 0$ tal que si $x \in (p, p + \delta)$ se tiene $|f(x) - L| < \varepsilon$. Si en cambio ocurre que $\forall K \in \reales$ existe un $\delta > 0$ tal que si $x \in (p, p + \delta)$ se tiene $f(x) > K$ entonces decimos que $f$ \textbf{diverge por la derecha a $+\infty$} en $p$. Análogamente se define para $-\infty$.		
		\item
		Sea $f: (a, p) \rightarrow \reales$. Decimos que $f$ \textbf{converge por la izquierda} a un valor $L \in \reales$ en $p$ si $\forall \varepsilon > 0$ existe un $\delta > 0$ tal que si $x \in (p - \delta, p)$ se tiene $|f(x) - L| < \varepsilon$. Si en cambio ocurre que $\forall K \in \reales$ existe un $\delta > 0$ tal que si $x \in (p - \delta, p)$ se tiene $f(x) > K$ entonces decimos que $f$ \textbf{diverge por la derecha a $+\infty$} en $p$. Análogamente se define para $-\infty$.
	\end{itemize}
\end{define}

Existen muchas combinaciones posibles para cubrir todos los casos. Aquí hemos puesto las básicas. En el caso de la convergencia por la derecha e izquierda, los valores a los que converge la función se dicen \textbf{límites laterales}.

El primer paso en el estudio de límites es ver que efectivamente una función solo puede converger a un único valor. Por comodidad, solo enunciamos el resultado para límites no laterales en un punto. Para funciones en el infinito y límites laterales es similar.

\begin{prop}
	Sea $f: A \rightarrow \reales$ y $p$ punto de acumulación de $A$. Si $f$ converge a $L_1$ y $L_2$ en $p$ entonces no $L_1 = L_2$.
\end{prop}

\begin{define}
	Si $f: A \rightarrow \reales$ converge en $p$ punto de acumulación de $A$ a un valor $L \in \reales$ este valor es único y se denomina \textbf{límite} de la función $f$ en $p$. Se denota por $\lim_{x \rightarrow p} f(x) = L$.
\end{define}

Como hemos dicho, el límite formaliza la idea de que una función se acerque a un valor $L$ conforme el input se acerca a otro valor $p$. Obviamente es necesario que nos podamos acercar a $p$, es por esto que pedimos que sea punto de acumulación del dominio. La definición de límite nos garantiza que da igual de que forma nos acerquemos a $p$, que $f$ siempre va a acercarse a $L$. El siguiente teorema especifica más esta idea:
\begin{theorem}[Caracterización del límite por sucesiones]
	Sea $f: A \rightarrow \reales$ una función y $p$ un punto de acumulación de $A$. Entonces dado $L \in \reales$ son equivalentes:
	\begin{itemize}
		\item
		$\lim_{x \rightarrow p} f(x) = L$.
		\item
		Para toda sucesión $\{a_n \}_n$ tal que $a_n \neq p\ \forall n$ que converja a $p$ se tiene $\lim_{n \rightarrow +\infty} f(a_n) = L$ (este último límite es de sucesiones).
	\end{itemize}
\end{theorem}

Generalmente, el teorema anterior se usa para demostrar que algunos límites no existen:
\begin{ejem}
	El límite de $f(x) = \sin (\frac{1}{x})$ conforme $x$ tiende a $0$ no existe. En efecto, tomando las siguientes sucesiones:
	\begin{align*}
		x_n = \frac{1}{2n\pi} \qquad y_n = \frac{1}{2n\pi + \frac{\pi}{2}}
	\end{align*}
	se puede comprobar fácilmente que $\lim_{n\rightarrow\infty} x_n = 0$ y $\lim_{n\rightarrow\infty} y_n = 0$ por lo que los límites $\lim_{n\rightarrow\infty}f(x_n) = 0$ y $\lim_{n\rightarrow\infty}f(y_n) = 1$ y el teorema anterior demuestran que no existe el límite.
\end{ejem}

Pero veremos que también se puede usar para demostrar la existencia de algunos límites.\\ 
Es importante tener herramientas para poder calcular límites sin tener que recurrir a la definición.

\begin{theorem}[Aritmética de los límites]
	Sean $f: A \rightarrow \reales$ y $g: B \rightarrow \reales$ dos funciones tales que $p$ sea un punto de acumulación de $A$ y $B$, y supongamos que $\lim_{x \rightarrow p} f(x) = L_f$ y $\lim_{x \rightarrow p} g(x) = L_g$. Entonces se cumple:
	\begin{itemize}
		\item
		Si $a \in \reales$ entonces $\lim_{x \rightarrow p} af(x) = aL_f$.
		\item
		$\lim_{x \rightarrow p} f(x) + g(x) = L_f + L_g$.
		\item
		$\lim_{x \rightarrow p} f(x)g(x) = L_f L_g$.
		\item
		Si $L_g \neq 0$ entonces $\lim_{x \rightarrow p} \frac{f(x)}{g(x)} = \frac{L_f}{L_g}$.
	\end{itemize}
\end{theorem}

\begin{theorem}[Orden de los límites]
	Sean $f,g: A \rightarrow \reales$ y $p$ un punto de acumulación de $A$. Supongamos que $\lim_{x\rightarrow p} f(x) = L_f$ y $\lim_{x\rightarrow p} g(x) = L_g$.
	\begin{itemize}
		\item
		Si $L_f < L_g$ entonces existe un entorno reducido $U$ de $p$ tal que $f(x) < g(x)$ para todo $x \in U \cap A$. TODO: Hemos definido entorno reducido?
		\item
		Si $f(x) < g(x)$ para todo $x \in U \cap A$ en un entorno reducido $U$ de $p$ entonces $L_f \leq L_g$.
	\end{itemize}
\end{theorem}

\begin{theorem}[Regla del sandwich]
	Sean $f,g,h: A \rightarrow \reales$ y $p$ un punto de acumulación de $A$, tales que se cumpla $f(x) \leq h(x) \leq g(x)$ para todo $x \in A$ y $\lim_{x\rightarrow p} f(x) = \lim_{x\rightarrow p} g(x) = L$, con $L$ posiblemente infinito. Entonces $\exists \lim_{x\rightarrow p} h(x) = L$.
\end{theorem}

\begin{ejem}
	Calculamos el límite
	\begin{equation*}
		\lim_{x\rightarrow 0} \frac{x^2 \sin(\frac{1}{x})}{x + 3\sqrt{x}}.
	\end{equation*}
	Primero notamos que es igual a 
	\begin{equation*}
		\lim_{x\rightarrow 0} \frac{x^{\frac{3}{2}} \sin(\frac{1}{x})}{\sqrt{x} + 3}.
	\end{equation*}
	cuyo numerador vamos a demostrar que tiende a $0$, y como su denominador tiende a $3$ vamos a tener que el límite original vale $0$.
	Como $-1 \leq \sin(x) \leq 1$ se tiene $-1 \leq \sin(\frac{1}{x}) \leq 1$ y como la función solo está definida para $x \geq 0$ tendremos $-x^{\frac{3}{2}} \leq x^{\frac{3}{2}}\sin(\frac{1}{x}) \leq x^{\frac{3}{2}}$, y como el mayorando y el minorando tienden a $0$ por la regla del sandwich $\exists \lim_{x\rightarrow 0}x^{\frac{3}{2}}\sin(\frac{1}{x}) = 0$.
\end{ejem}

Otra herramienta poderosa para calcular límites que abre las puertas al campo del análisis asintótico son las equivalencias.

\begin{define}
	Sean $f,g: A \rightarrow \reales$ y $p$ un punto interior de $A$. Se dice que $f$ y $g$ son \textbf{equivalentes} en $p$ si existe una función $h:A \rightarrow \reales$ que satisface $\lim_{x \rightarrow p} h(x) = 1$ y $f(x) = g(x)h(x)$ para todo $x \in A \smallsetminus \{p \}$. Lo denotamos por $f \sim_p g$.
\end{define}

\begin{define}
	Sean $f,g: (a, +\infty) \rightarrow \reales$. Se dice que $f$ y $g$ son \textbf{equivalentes en el infinito} positivo si existe una función $h:A \rightarrow \reales$ que satisface $\lim_{x \rightarrow +\infty} h(x) = 1$ y $f(x) = g(x)h(x)$ para todo $x \in (b, +\infty)$ con $b \geq a$. Lo denotamos por $f \sim_{+\infty} g$. También se definen análogamente para el infinito negativo.
\end{define}

\begin{prop}\label{prop_equivalencia}
	Sean $f,g: A \rightarrow \reales$ y $p$ un punto interior de $A$. Supongamos que en un entorno reducido $U$ de $p$ se tiene $g(x) \neq 0$ para todo $x \in U \cap A$. Entonces son equivalentes:
	\begin{itemize}
		\item
		$\lim_{x\rightarrow p} \frac{f(x)}{g(x)} = 1$.
		\item
		$f \sim_p g$.
	\end{itemize}
\end{prop}

Esta proposición permite una demostración más fácil de distintas equivalencias y da una mejor intuición que la definición. Podríamos tomar la definición de equivalencias como la equivalencia del teorema, pero estaríamos excluyendo el caso en el que ambas funciones tengan ceros en todo entorno reducido de $p$, y además haría de la relación de ser equivalente una relación no equivalente.

\begin{prop}
	\begin{itemize}
		\item
		Las relaciones $\sim_p$ y $\sim_{\infty}$ son relaciones binarias de equivalencia (RBE).
		
		\item
		Si $f_1 \sim_p g_1$ y $f_2 \sim_p g_2$ entonces $f_1 f_2 \sim_p g_1 g_2$.
		
		\item
		Si $f_1 \sim_p g_1$, $f_2 \sim_p g_2$ y $f_2,g_2$ no se anulan en un entorno reducido de $p$ entonces $\frac{f_1}{f_2} \sim_p \frac{g_1}{g_2}$.
		
		\item
		TODO: Comp
	\end{itemize}
\end{prop}

\begin{prop}[Lista básica de equivalencias]
	Se cumple:
	\begin{itemize}
		\item
		$\sin(x) \sim_0 x$.
		
		\item
		$1 - \cos(x) \sim_0 \frac{x^2}{2}$.
		
		\item
		$\tan(x) \sim_0 x$.		
		
		\item
		Si $a > 1$, $a^x - 1\sim_0 x\log(a)$. En concreto $e^x - 1 \sim_0 x$.

		\item
		$\log(1 + x) \sim_0 x$.		
		
	\end{itemize}
\end{prop}

Ahora podemos usarlas para calcular algunos límites.

\begin{ejem}
	\begin{enumerate}
		\item
		\begin{equation*}
			\lim_{x\rightarrow 0} \frac{x^2(1-\cos(x))}{\sin^4(x)} = \lim_{x\rightarrow 0} \frac{x^2 \frac{x^2}{2}}{x^4} = \frac{1}{2}.
		\end{equation*}
		\item
		Sean $a, b$ constantes reales y positivas. Si $a \geq b$:
		\begin{equation*}
			\lim_{x\rightarrow 0} \frac{a^x - b^x}{x} = \lim_{x\rightarrow 0} b^x \frac{\frac{a^x}{b^x} - 1}{x} = \lim_{x\rightarrow 0} \frac{x\log(\frac{a}{b})}{x} = \log(\frac{a}{b}).
		\end{equation*}
		Si $a < b$, dividimos por $a^x$ en vez de $b^x$ y terminamos obteniendo el mismo resultado.
	\end{enumerate}
\end{ejem}

Más concretamente, la proposición \eqref{prop_equivalencia} es una forma más clara de ver que la tendencia de dos funciones equivalentes en un punto $p$ (o en el infinito) alrededor de $p$ es ``la misma''. También existe notación para expresar que una función tiende a $0$ más rápido que otra:
TODO: Generalizarla al estilo de las equivalencias?
\begin{define}
	Supongamos que $g: I \rightarrow \reales$ es una función definida en un intervalo abierto $I$, tal que $g(p) = 0$ en $p \in I$ y $g(x) \neq 0$ en un entorno reducido de $p$. Decimos que otra función $f: A \rightarrow \reales$ con $p \in \interior{A}$ es una \textbf{o pequeña} de $g$ en $p$ si
	\begin{equation*}
		\lim_{x \rightarrow p} \frac{f(x)}{g(x)} = 0
	\end{equation*}
	y en tal caso escribimos $f \in o_{p}(g)$, donde $o_{p}(g)$ es el conjunto de todas las funciones o pequeña de $g$ en $p$.
\end{define}

Generalmente, el punto $p$ de la notación $o_{p}(g)$ se excluye en los casos en los que sea obvio de que punto se habla. También se suele realizar el siguiente abuso de notación, en vez de hablar de $o_{p}(g)$ como conjunto se trata como una ``función'':
\begin{equation*}
	f(x) = o_p (g(x)).
\end{equation*}
Esto simplemente significa que $f$ es igual a alguna función del conjunto $o_p(g(x))$.\\ 
Aunque hayamos introducido la definición con cierta generalidad, su mayor uso será el la sección de Taylor, considerando o pequeñas de funciones de la forma $(x-p)^n$ para $p \in \reales$ y $n \in \naturales$. Es por esto que introducimos algunas propiedades de estas o pequeñas aquí:

\begin{prop}
	Para toda pareja de naturales $m \leq n$:
	\begin{equation*}
		o((x-p)^m) \subseteq o((x-p)^n).
	\end{equation*}
\end{prop}

\begin{prop}
	Para toda pareja de naturales $m \leq n$:
	\begin{equation*}
		o((x-p)^m) + o((x-p)^n) = o((x-p)^m).
	\end{equation*}
	(Aquí la suma denota la suma estándar de conjuntos: $A+B = \{a+b\ |\ a\in A,\ b\in B \}$.)
\end{prop}


TODO: limites en un punto e infinito, laterales, caracterización por sucesiones, operaciones con limites, limite inferior y superior, limites de funciones monótonas, equivalencias, notacion o y O, condición de cauchy

\subsection{Continuidad}
\begin{define}
	Sea $f: A \rightarrow \reales$ una función. Decimos que $f$ es \textbf{continua} en un punto $a \in A$ si y solo si se cumple una de estas dos condiciones:
	\begin{enumerate}
		\item
		$a$ es un punto aislado de $A$.
		\item
		$a$ es un punto de acumulación de $A$ y $\lim_{x \rightarrow a} f(x) = f(a)$.
	\end{enumerate}
	Si $f$ es continua en todo $p \in P \subseteq A$ se dice que $f$ es continua en $P$, y si es continua en todo punto de su dominio simplemente se dice continua.
\end{define}

\begin{define}
	Decimos que una función $f: (a, b) \rightarrow \reales$ es \textbf{continua de Lipschitz} si $\exists K \in \reales$ tal que
	\begin{equation*}
		|f(x) - f(y)| \leq K|x - y|\ \forall x,y \in (a, b).
	\end{equation*}
\end{define}

\begin{prop}
	Una función continua de Lipschitz es continua.
\end{prop}

\begin{proof}
	Tomar $\delta = \frac{\varepsilon}{K}$ en la definición de continuidad. 
\end{proof}

\begin{prop}
	Si $f: A \rightarrow \reales$ es función continua en $p$ y $g: B \rightarrow \reales$ también, entonces $f + g$, $fg$, $-f$ también lo son. Además, si $g(p) \neq 0$ entonces $\frac{f}{g}$ también lo es.
\end{prop}

\begin{proof}
	Aplicar los resultados correspondientes a límites de funciones. En el caso que una de las funciones sea continua en $p$ por ser $p$ punto aislado del dominio, entonces $p$ será punto aislado del dominio de $f+g$, $fg$ y $\frac{f}{g}$ y así serán continuas.
\end{proof}

\begin{prop}
	Sean $f: A \rightarrow B$ y $g: B \rightarrow C$ funciones continuas en $p\in A$ y $f(p)$ respectivamente. Entonces $g \circ f$ es continua en $p$.
\end{prop}

\begin{prop}
	Una función $f: A \rightarrow B \subseteq \reales$ es continua si y solo si para todo abierto $U \subseteq \reales$ el conjunto $f^{-1}(B \cap U)$ es abierto.
\end{prop}

\begin{prop}
	Si $f: A \rightarrow \reales$ es continua y $A$ es compacto entonces $f(A)$ es compacto. 
\end{prop}

\begin{theorem}[Teorema de Weierstrass]
	Si $f: A \rightarrow \reales$ es continua y $A$ es compacto entonces $f$ alcanza su máximo y su mínimo en $A$.
\end{theorem}

\begin{prop}[Teorema de Bolzano]
	Si $f: [a, b] \rightarrow \reales$ es continua tal que $f(a)f(b) < 0$ entonces $\exists x_0 \in [a, b]$ tal que $f(x_0) = 0$.
\end{prop}

\begin{theorem}[Teorema de los valores intermedios]
	Si $f: [a, b] \rightarrow \reales$ es continua entonces $f(A)$ es un intervalo.
\end{theorem}

\begin{define}
	Una función $f: A \rightarrow \reales$ es uniformemente continua si $\forall \varepsilon > 0$ existe un $\delta > 0$ tal que para todo $x,y \in A$ se tiene que si $|x-y| < \delta$ entonces $|f(x) - f(y)| < \varepsilon$.
\end{define}

\begin{prop}
	Una función continua de Lipschitz es uniformemente continua y una función uniformemente continua es continua.
\end{prop}

\begin{theorem}[Teorema de Borel]
	Una función continua definida en un conjunto compacto es uniformemente continua en tal conjunto.
\end{theorem}

TODO: funciones continuas monotonas, definiciones, continuidad lateral, operaciones, lipschitz, holder, uniformemente continua, teoremas del valor intermedio (bolzano), weierstrass, borel, 








\newpage
\section{Derivabilidad de funciones reales}
El objetivo elemental de la derivada es el estudio de como varia cierta función. TODO: Explicación 

\begin{define}
	Sea $f: A \rightarrow \reales$ una función y $p \in A$ un punto interior de $A$. Decimos que $f$ es \textbf{derivable} en $p$ si y solo si existe el siguiente límite
	\begin{equation*}
		\lim_{x \rightarrow p} \frac{f(x) - f(p)}{x - p}
	\end{equation*}
	y en caso de que exista, el valor de tal límite se denomina \textbf{derivada} de $f$ en el punto $p$ y se denota $f'(p)$. Si $f$ es derivable en todo punto de un conjunto $B \subseteq A$ se dice \textbf{derivable} en $B$ y se define la \textbf{función derivada} como la función que en cada punto de $B$ toma el valor de la derivada de $f$ en ese punto. Tal función se denota por $f'$, independientemente del conjunto $B$ que estemos considerando. 
\end{define}

\begin{ejem}
	$f(x) = x$ es derivable en todo $\reales$ y su derivada es igual a $1$. En efecto, si $p \in \reales$
	\begin{equation*}
		\lim_{x \rightarrow p} \frac{f(x) - f(p)}{x - p} = \lim_{x \rightarrow p} \frac{x - p}{x - p} = \lim_{x \rightarrow p} 1 = 1.
	\end{equation*}
\end{ejem}
TODO: Derivadas de $x^n$, trigonometricas, exponenciales, logaritmos. 

Una función derivable posee cierta ``suavidad'' que es más fuerte que una función continua:

\begin{prop}
	Si $f: A \rightarrow \reales$ es derivable en $p \in A$ entonces $f$ es continua en $p$.
\end{prop}

\begin{proof}
	Como $p$ es punto interior de $A$, es también punto de acumulación de $A$. Por eso
	\begin{align*}
		\lim_{x\rightarrow p} f(x) = \lim_{x\rightarrow p} \frac{f(x) - f(p)}{x - p} (x-p) + f(p) = f'(p)*0 + f(p) = f(p)
	\end{align*}
	implica que $f$ es continua en $p$.
\end{proof}

Otra propiedad importante de las funciones derivables es que se pueden ``aproximar'' en cierto sentido por funciones más simples, las funciones afines, en cada punto. Esto no parece intuitivo de primeras (la noción de derivada solo parecía tener que ver con el cambio), y de hecho para funciones de varias variables (que no tratamos en este documento) esto no es cierto. Primero, tenemos que definir una noción adecuada de ``ser aproximable por una función afín''.

\begin{define}
	Sea $f: A \rightarrow \reales$ una función y $p \in A$ un punto interior de $A$. Decimos que $f$ es \textbf{diferenciable} en $p$ si y solo si existe una función lineal $T$ en un entorno de $p$ tal que
	\begin{equation*}
		\lim_{x \rightarrow p} \frac{f(x) - f(p) - T(x-p)}{x-p} = 0.
	\end{equation*}
	La función $T$ se denomina \textbf{diferencial} de $f$ en $p$.
\end{define}

Reescribiendo la definición obtenemos
\begin{equation*}
	f(x) = f(p) + T(x-p) + o_p(x-p)
\end{equation*}
lo que implica que cerca del punto $p$ la función afín $f(p) + T(x-p)$ aproxima a $f(x)$ de forma que el resto de la aproximación tiende a $0$ más rápido que $x-p$. Esto resulta ser equivalente a que la función $f$ sea derivable en un punto $p$:

\begin{prop}
	Una función $f$ es derivable en $p$ si y solo si es diferenciable en $p$.
\end{prop}

Esta forma de aproximar funciones es muy pobre, ya que solo nos sirve cerca de puntos donde sepamos el valor de la función y no tenemos una forma de acotar el error.
La idea de aproximar funciones por funciones más simples se expande en la sección de desarrollos de Taylor, en los que se busca aproximar funciones por polinomios. Estas aproximaciones resultan ser más precisas que usar funciones afines.\\ 
Como es costumbre, relacionamos las operaciones aritméticas con el concepto de derivada.

\begin{prop}
	Sean $f: A \rightarrow \reales$ y $g: B \rightarrow \reales$ funciones, con $p \in A \cap B$ un punto interior de $A$ y $B$. Si $f$ y $g$ son derivables en $p$, entonces las funciones $f + g$, $fg$ y $af$ para todo $a \in \reales$ son derivables en $p$, además sus derivadas valiendo $f'(p) + g'(p)$, $f'(p)g(p) + f(p)g'(p)$ y $af'(p)$. Si $g(p) \neq 0$ entonces $\frac{f}{g}$ es derivable en $p$, y su derivada vale $\frac{f'(p)g(p) - f(p)g'(p)}{(g(p))^2}$.
\end{prop}

\begin{prop}[Regla de la cadena]
	Sean $f: A \rightarrow \reales$ y $g: B \rightarrow \reales$ funciones, con $p$ punto interior de $B$, $g(p)$ punto interior de $A$ y además $g(B) \subseteq A$. Entonces la función $g \circ f$ es derivable en $p$ y se tiene $(g \circ f)'(p) = g'(f(p))f'(p)$.
\end{prop} 

Estas proposiciones sirven para obtener derivadas de muchas funciones una vez se conocen unas pocas derivadas de funciones elementales:
\begin{prop}[Tabla de derivadas]

\end{prop}
La derivada tiene una relación importante con los máximos y mínimos de una función.

\begin{prop}
	Sea $f: A \rightarrow \reales$ una función con un máximo (mínimo) local en $p$ un punto interior de $A$. Si $f$ es derivable en $p$ entonces $f'(p) = 0$.
\end{prop}
\begin{proof}
	Hacemos la demostración para un máximo local en $p$. Como $p$ es un máximo local de $f$, existirá un entorno intervalo $E=(p-\varepsilon,\ p+\varepsilon)$ para él que $f(p) \geq f(x)$ para todo $x \in E$. Esto implica que en este intervalo se tiene $f(p) - f(x) \geq 0$. Si $x_{-} \in E$ y $x_{-} < p$ se tiene $p - x_{-} \geq 0$ y por tanto $\frac{f(p) - f(x_{-})}{p - x_{-}} \geq 0$ y por el orden de los límites $f'(p) \geq 0$. En cambio, si $x_{+} \in E$ con $x_{+} > p$ se tendrá $p - x_{+} \leq 0$, por lo que $\frac{f(p) - f(x_{-})}{p - x_{-}} \leq 0$ y así $f'(p) \leq 0$. Como tenemos $0 \geq f'(p) \geq 0$ por las propiedades del orden se tiene $f'(p) = 0$.
\end{proof}

Esta relación se expande en la sección de comportamiento local. La hemos presentado aquí para poder hacer la demostración de los siguientes teoremas.

\begin{theorem}[Teorema de Rolle]
	Sea $f: [a, b] \rightarrow \reales$ continua en $[a, b]$ y derivable en $(a, b)$. Si se tiene $f(a) = f(b)$ entonces $\exists c \in (a, b)$ tal que $f'(c) = 0$.
\end{theorem}
\begin{proof}
	Como $f$ es continua en $[a, b]$, por el teorema de Weierstrass obtendrá su máximo y mínimo globales en el intervalo. Si alguno de estos está dentro de $(a, b)$ entonces será un máximo o mínimo local, por lo que tendremos $f'(c) = 0$ con $c$ el máximo o mínimo. Si ninguno está dentro de $(a, b)$ es necesario que uno sea $a$ y el otro $b$, pero al tener $f(a) = f(b)$ esto implica que la función es constante en $[a, b]$ y por tanto $f'(x) = 0$ para todo $x \in (a, b)$.
\end{proof}

\begin{theorem}[Teorema del valor medio, o los incrementos finitos de Lagrange]
	Sea $f: [a, b] \rightarrow \reales$ continua en $[a, b]$ y derivable en $(a, b)$. Entonces existirá $c \in (a, b)$ tal que
	\begin{equation*}
		f'(c) = \frac{f(b) - f(a)}{b - a}.
	\end{equation*}
\end{theorem}
\begin{proof}
	Se define $g(x) = f(x) - x\frac{f(b) - f(a)}{b - a}$ y se observa que $g(a) = g(b)$. Aplicando el teorema de Rolle a $g$ se obtiene el resultado.
\end{proof}

\begin{theorem}[Teorema de los incrementos finitos de Cauchy]
	Sean $f,g: [a, b] \rightarrow \reales$ continuas en $[a, b]$, derivables en $(a, b)$ y con $g(a) \neq g(b)$. Entonces existirá $c \in (a, b)$ tal que
	\begin{equation*}
		f'(c)(g(b) - g(a)) = g'(c)(f(b) - f(a)).
	\end{equation*}
\end{theorem}

\begin{theorem}[Teorema de Darboux]
	Sea $f:A \rightarrow \reales$ continua y derivable en $A$ con $A$ un intervalo abierto. Si $a,b \in A$ con $a<b$ y $\alpha \in \reales$ es un valor entre $f'(a)$ y $f'(b)$ entonces existe un $c \in [a, b]$ tal que $f'(c) = \alpha$.
\end{theorem}

TODO: Inversas, calcular algunas derivadas, introducir las exponeciales en algun sitio

\subsection{Taylor I}

\begin{define}
	Sea $f: A \rightarrow \reales$ una función definida en un entorno de $x_0$. Decimos que un polinomio $p_n$ de grado $n$ es un \textbf{desarrollo polinomial} de $f$ en $x_0$ si se tiene $f(x) - p_n(x) = o_{x_0}((x-x_0)^n)$.
\end{define}

\begin{prop}
	Sea $f: A \rightarrow \reales$ y $x_0 \in \interior{A}$. Si $f$ es $n-1$ veces derivable en $p$ entonces son equivalentes:
	\begin{itemize}
		\item
		$f(x) = o((x-x_0)^n)$.
		\item
		Existe la $n$-ésima derivada en $x_0$ y además $f(x_0) = f'(x_0) = \cdots = f^{(n)}(x_0) = 0$.
	\end{itemize}
\end{prop}

\begin{prop}
	Si $f$ admite un desarrollo polinomial $p_n$ de grado $n$ en un punto $x_0$ entonces todo desarrollo polinomial de grado $n$ en $x_0$ es igual a $p_n$.
\end{prop}

\begin{proof} TODO: Se puede hacer más claro\\ 
	Sea $q_n$ un desarrollo polinomial de $f$ de grado $n$ en $x_0$. Aplicando el teorema anterior a $f(x) - q_n(x)$ obtenemos que $f^{(k)}(x_0) = q_n^{(k)}(x_0)$ para todo $k=0,\ 1,\dots\ n$. Si consideramos los $n+1$ coeficientes del polinomio $q_n$ como indeterminados obtenemos de $f^{(k)}(x_0) = q_n^{(k)}(x_0)$ un sistema de $n+1$ ecuaciones lineales que son linealmente independientes entre sí, por tanto tal sistema es compatible determinado y tiene una única solución.
\end{proof}

\begin{theorem}[Teorema de Taylor]
	Sea $f: A \rightarrow \reales$ una función $n-1$ veces derivable en un entorno de $x_0 \in \reales$, con $n$-ésima derivada en $x_0$. Entonces $f$ admite un desarrollo polinomial de grado $n$ en $x_0$
	\begin{equation*}
		f(x) = \sum_{m=0}^{n} \frac{f^{(m)}(x_0)}{m!} (x-x_0)^m + o_{x_0}((x-x_0)^n).
	\end{equation*}
	Tal polinomio se llama \textbf{polinomio de Taylor} de $f$ en $x_0$ de grado $n$, y lo denotamos por $P_{n;x_0}(x)$.
\end{theorem}

\begin{theorem}[Teoremas del resto]
	Sea $f$ una función $n+1$ veces derivable en un entorno $A$ de $x_0$. Se tiene:
	\begin{itemize}
		\item
		Para todo $x \in A$ existe un punto $c$ entre $x_0$ y $x$ tal que
		\begin{equation*}
			f(x) - P_{n;x_0}(x) = f^{(n+1)}(c)\frac{(x-x_0)^{n+1}}{(n+1)!}.
		\end{equation*}
		Esta fórmula recibe el nombre de resto de Lagrange.		
		
		\item
		Para todo $x \in A$ existe un punto $c$ entre $x_0$ y $x$ tal que
		\begin{equation*}
			f(x) - P_{n;x_0}(x) = f^{(n+1)}(c)\frac{(x-c)^n (x-x_0)}{n!}.
		\end{equation*}
		Esta fórmula recibe el nombre de resto de Cauchy.
	\end{itemize}
\end{theorem}

TODO: Desarrollos de funciones resultantes de operaciones (sumas, multiplicaciones, derivadas, ``integrales'', componer, dividir), equivalencias, ejemplos de desarrollos

\subsection{Comportamiento local}

El teorema de Taylor nos permite obtener una caracterización del comportamiento local de una función en lo que respecta al crecimiento y decrecimiento.

\begin{cor}
	Sea $f$ una función derivable $n-1$ veces en un entorno $E$ de un punto $x_0$, tal que exista la derivada $n$-ésima en $x_0$ con $n$ par. Supongamos que se cumple $f'(x_0) = f''(x_0) = \cdots = f^{(n-1)}(x_0) = 0$ y que $f^{(n)}(x_0) \neq 0$. Entonces si $f^{(n)}(x_0) < 0$ $x_0$ es un máximo local, y si $f^{(n)}(x_0) > 0$ $x_0$ es un mínimo local. Si $n$ fuera impar, si $f^{(n)}(x_0) < 0$ $f$ es localmente decreciente en $x_0$ y si $f^{(n)}(x_0) > 0$ $f$ es localmente creciente en $x_0$.
\end{cor}

Aunque este corolario sea todo lo que vayamos a necesitar, es importante dar dos resultados más pequeños que generalmente son suficientes.

\begin{prop}
	Sea $f: I \rightarrow \reales$ una función derivable en $I$ y dos veces derivable en un punto $x_0 \in I$, tal que $f'(x_0) = 0$.
	\begin{itemize}
		\item
		Si $f''(x_0) > 0$ entonces $x_0$ es un mínimo local.
	
		\item
		Si $f''(x_0) < 0$ entonces $x_0$ es un máximo local.
	\end{itemize}
\end{prop}

\begin{define}
	Sea $f$ una función derivable en $x_0$. $x_0$ se dice \textbf{punto crítico} de $f$ si $f'(x_0)=0$.
\end{define}

\begin{prop}
	Sea $f: [a, b] \rightarrow \reales$ derivable en $(a, b)$ y continua en $[a, b]$.
	\begin{itemize}
		\item
		Si $f'(x) > 0$ para todo $x \in (a, b)$ entonces $f$ es creciente en $[a, b]$.
		
		\item
		Si $f'(x) < 0$ para todo $x \in (a, b)$ entonces $f$ es decreciente en $[a, b]$.
	\end{itemize}
\end{prop}

TODO: Puntos críticos, crecimiento y decrecimiento, convexidad y concavidad










\newpage
\section{Integrabilidad de funciones reales}

\subsection{Cálculo de primitivas}

\subsection{La integral de Riemann y Darboux}

\subsection{Teoremas fundamentales}

\subsection{Integrabilidad impropia}

\subsection{Funciones beta y gamma}

\subsection{Integrales definidas no elementales}
Es interesante que incluso en el caso que una función no tenga primitiva expresable con funciones elementales se puede dar un valor exacto a algunas integrales definidas. Generalmente, estas integrales se hacen todas de forma diferente y existen muchos trucos para calcularlas, aquí presentamos solo algunos.

\begin{prop}[Regla de King]
	Si $f: (a, b) \rightarrow \reales$ es integrable entonces:
	\begin{equation*}
		\int_a^b f(x) \,dx = \int_a^b f(a+b-x) \,dx.
	\end{equation*}
\end{prop}
\begin{proof}
	Aplicar la sustitución $u = a + b - x$.
\end{proof}

\begin{ejem}
	Procedemos al cálculo de integrales de la forma
	\begin{equation*}
		I = \int_a^b \frac{f(x)}{f(x) + f(a + b - x)} \,dx.
	\end{equation*}
	Por la regla de King
	\begin{equation*}
		I = \int_a^b \frac{f(x)}{f(x) + f(a + b - x)} \,dx = \int_a^b \frac{f(a+b-x)}{f(x) + f(a + b - x)} \,dx.
	\end{equation*}
	Tomando dos veces $I$, una sustituyendo la primera expresión y después sustituyendo la segunda se obtiene
	\begin{equation*}
		2I = \int_a^b \frac{f(x) + f(a + b - x)}{f(x) + f(a + b - x)} \,dx = \int_a^b 1 \,dx = a - b,
	\end{equation*}
	y finalmente
	\begin{equation*}
		\int_a^b \frac{f(x)}{f(x) + f(a + b - x)} \,dx = \frac{a-b}{2}.
	\end{equation*}
	Por ejemplo, aplicando la fórmula obtendríamos
	\begin{equation*}
		\int_0^1 \frac{\arctan(x)}{\arctan(x) + \arctan(1 - x)} \,dx = \frac{1}{2}.
	\end{equation*}
\end{ejem}

\begin{ejem}
	\begin{equation*}
		\int_0^{\frac{\pi}{2}} \log(\tan x)dx = 0
	\end{equation*}
\end{ejem}

\begin{ejem}
	\begin{equation*}
		\int_0^{\frac{\pi}{2}} \log(\sin x)dx = \frac{-\pi}{2} \log(2)
	\end{equation*}
	Esta integral es bastante interesante y se puede calcular de muchas formas. La más elemental usa la regla de King, como detallamos ahora.
\end{ejem}

Aparte de la sustitución de la regla de King, otras sustituciones son útiles.

\begin{ejem}
	\begin{equation*}
		\int_0^{\infty} \frac{\log(x)}{(1+x)^2} \,dx = 0
	\end{equation*}
\end{ejem}

Otra técnica es la derivación bajo el signo integral


\begin{ejem}
	\begin{equation*}
		\int_0^{\infty} \frac{1 - e^{-x^2}}{x^2} dx
	\end{equation*}
\end{ejem}

\begin{ejem}
	\begin{equation*}
		\int_0^{\frac{\pi}{2}} (\log(\sin x))^2 dx
	\end{equation*}
\end{ejem}

\section{Series numéricas}

\subsection{Series de términos no negativos}

\subsection{Series de términos arbitrarios}





\section{Series funcionales y de potencias}

\subsection{Sucesiones y series de funciones}

\subsection{Convergencia uniforme}

\subsection{Series de potencias y Taylor II}


\newpage
\section{Anexo: Funciones trignométricas}
La introducción de las funciones trigonométricas en estos apuntes no ha sido de una manera rigurosa. Se asume que el lector ha aprendido trigonometría anteriormente, y allí se definen de una forma geométrica. Si hablamos en términos formales, podemos introducir las funciones trigonométricas mediante sus series de Taylor:

\begin{define}
	Las funciones \textbf{coseno} y \textbf{seno} se definen como
	\begin{equation*}
		\cos(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!} x^{(2n)}
	\end{equation*}
	y
	\begin{equation*}
		\sin(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!} x^{(2n+1)}
	\end{equation*}
	Ambas series convergen en todo $\reales$.
	La función \textbf{tangente} se define como $\tan(x) = \frac{\sin(x)}{\cos(x)}$.
	Aparte de estas, se definen la \textbf{secante}, \textbf{cosecante} y \textbf{cotangente} como $\sec(x) = \frac{1}{\cos(x)}$, $\csc(x) = \frac{1}{\sin(x)}$ y $\cot(x) = \frac{1}{\tan(x)}$ respectivamente.
\end{define}

Otra forma de introducirlas es mediante ecuaciones diferenciales, pero no lo hacemos aquí ya que no hemos desarrollado la teoría.\\ 

\begin{theorem}[Fórmula de Euler]
	\begin{equation*}
		e^{ix} = \cos(x) + i\sen(x)
	\end{equation*}
\end{theorem}

Con esta fórmula demostrar las siguientes identidades es fácil.

\begin{prop}
	\begin{eqnarray*}
		\cos(2\theta) = \cos^2(\theta) - \sin^2(\theta) \\ 
		\sin(2\theta) = 2\cos(\theta)\sin(\theta) \\ 
		\tan(2\theta) = \frac{2\tan(\theta)}{1 - \tan^2(\theta)} \\ 
		\cos(3\theta) = 4\cos^3(\theta) - 3\cos(\theta) \\ 
		\sin(3\theta) = -4\sin^3(\theta) + 3\sin(\theta)
	\end{eqnarray*}
\end{prop}

La identidad del ángulo triple tiene una consecuencia interesante: se puede usar para obtener una solución general a ecuaciones polinomiales de tercer grado.

\end{document}
